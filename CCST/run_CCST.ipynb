{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes: run data_generation_all.py to reproduce {generated_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python data_generation_all.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. import packages and select GPU if accessible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "#matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "#import pylab as pl\n",
    "#from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from scipy import sparse\n",
    "#from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from st_loading_utils import load_mPFC, load_mHypothalamus, load_her2_tumor, load_mMAMP, load_DLPFC, load_BC, load_mVC\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, ChebConv, GATConv, DeepGraphInfomax, global_mean_pool, global_max_pool  # noqa\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from datetime import datetime\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "# ================Specify data type firstly===============\n",
    "parser.add_argument( '--data_type', default='nsc', help='\"sc\" or \"nsc\", \\\n",
    "   refers to single cell resolution datasets(e.g. MERFISH) and \\\n",
    "   non single cell resolution data(e.g. ST) respectively') \n",
    "# =========================== args ===============================\n",
    "parser.add_argument( '--data_name', type=str, default='V1_Breast_Cancer_Block_A_Section_1', help=\"'MERFISH' or 'V1_Breast_Cancer_Block_A_Section_1\") \n",
    "parser.add_argument( '--lambda_I', type=float, default=0.3) #0.8 on MERFISH, 0.3 on ST\n",
    "parser.add_argument( '--data_path', type=str, default='generated_data/', help='data path')\n",
    "parser.add_argument( '--model_path', type=str, default='model') \n",
    "parser.add_argument( '--embedding_data_path', type=str, default='Embedding_data') \n",
    "parser.add_argument( '--result_path', type=str, default='results') \n",
    "parser.add_argument( '--DGI', type=int, default=1, help='run Deep Graph Infomax(DGI) model, otherwise direct load embeddings')\n",
    "parser.add_argument( '--load', type=int, default=0, help='Load pretrained DGI model')\n",
    "parser.add_argument( '--num_epoch', type=int, default=5000, help='numebr of epoch in training DGI')\n",
    "parser.add_argument( '--hidden', type=int, default=256, help='hidden channels in DGI') \n",
    "parser.add_argument( '--PCA', type=int, default=1, help='run PCA or not')   \n",
    "parser.add_argument( '--cluster', type=int, default=1, help='run cluster or not')\n",
    "parser.add_argument( '--n_clusters', type=int, default=5, help='number of clusters in Kmeans, when ground truth label is not avalible.') #5 on MERFISH, 20 on Breast\n",
    "parser.add_argument( '--draw_map', type=int, default=1, help='run drawing map')\n",
    "parser.add_argument( '--diff_gene', type=int, default=0, help='Run differential gene expression analysis')\n",
    "parser.add_argument( '--batch_size', type=int, default=512, help='training batch size')\n",
    "parser.add_argument( '--gpu_id', type=str, default=\"2\", help='default gpu id')\n",
    "args = parser.parse_args()\n",
    "iters=2 # for script testing\n",
    "# iters = 20 # for boxplotting\n",
    "args.embedding_data_path = './CCST/generated_data'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. DLPFC dataset (12 slides)\n",
    "\n",
    "change '${dir_}' to  'path/to/your/DLPFC/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"DLPFC\"\"\"\n",
    "setting_combinations = [[7, '151507'], [7, '151508'], [7, '151509'], [7, '151510'], [5, '151669'], [5, '151670'], [5, '151671'], [5, '151672'], [7, '151673'], [7, '151674'], [7, '151675'], [7, '151676']]\n",
    "for setting_combi in setting_combinations:\n",
    "   args.n_clusters = setting_combi[0]  # 7\n",
    "\n",
    "   args.data_name = setting_combi[1]  # '151673'\n",
    "   dataset = setting_combi[1]\n",
    "   args.data_type = 'nsc'\n",
    "   dir_ = './benchmarking_data/DLPFC12'\n",
    "   ad = load_DLPFC(root_dir=dir_, section_id=args.data_name)\n",
    "   aris = []\n",
    "   args.embedding_data_path = args.embedding_data_path +'/'+ args.data_name +'/'\n",
    "   args.model_path = args.model_path +'/'+ args.data_name +'/'\n",
    "   args.result_path = args.result_path +'/'+ args.data_name +'/'\n",
    "   if not os.path.exists(args.embedding_data_path):\n",
    "      os.makedirs(args.embedding_data_path) \n",
    "   if not os.path.exists(args.model_path):\n",
    "      os.makedirs(args.model_path) \n",
    "   args.result_path = args.result_path+'lambdaI'+str(args.lambda_I) +'/'\n",
    "   if not os.path.exists(args.result_path):\n",
    "      os.makedirs(args.result_path) \n",
    "   print ('------------------------Model and Training Details--------------------------')\n",
    "   print(args) \n",
    "   \n",
    "   for iter_ in range(iters):\n",
    "\n",
    "      \n",
    "      if args.data_type == 'sc': # should input a single cell resolution dataset, e.g. MERFISH\n",
    "         from CCST_merfish_utils import CCST_on_MERFISH\n",
    "         CCST_on_MERFISH(args)\n",
    "      elif args.data_type == 'nsc': # should input a non-single cell resolution dataset, e.g. V1_Breast_Cancer_Block_A_Section_1\n",
    "         from CCST_ST_utils import CCST_on_ST\n",
    "         preds = CCST_on_ST(args)\n",
    "      else:\n",
    "         print('Data type not specified')\n",
    "\n",
    "      # calculate metric ARI\n",
    "      obs_df = ad.obs.dropna()\n",
    "      # print(preds)\n",
    "      # print(obs_df['original_clusters'].to_list())\n",
    "      ARI = adjusted_rand_score(np.array(preds)[:, 1], obs_df['original_clusters'].to_list())\n",
    "      \n",
    "      print('Dataset:', dataset)\n",
    "      print('ARI:', ARI)\n",
    "      aris.append(ARI)\n",
    "   print('Dataset:', dataset)\n",
    "   print(aris)\n",
    "   print(np.mean(aris))\n",
    "   with open('ccst_aris.txt', 'a+') as fp:\n",
    "      fp.write('DLPFC' + dataset + ' ')\n",
    "      fp.write(' '.join([str(i) for i in aris]))\n",
    "      fp.write('\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. BC/MA datasets (2 slides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"BC\"\"\"\n",
    "setting_combinations = [[20, 'section1']]\n",
    "for setting_combi in setting_combinations:\n",
    "   args.n_clusters = setting_combi[0]\n",
    "\n",
    "   args.data_name = setting_combi[1]\n",
    "   dataset = setting_combi[1]\n",
    "   args.data_type = 'nsc'\n",
    "   dir_ = './benchmarking_data/BC'\n",
    "   ad = load_BC(root_dir=dir_, section_id=args.data_name)\n",
    "   aris = []\n",
    "   args.embedding_data_path = args.embedding_data_path +'/'+ args.data_name +'/'\n",
    "   args.model_path = args.model_path +'/'+ args.data_name +'/'\n",
    "   args.result_path = args.result_path +'/'+ args.data_name +'/'\n",
    "   if not os.path.exists(args.embedding_data_path):\n",
    "      os.makedirs(args.embedding_data_path) \n",
    "   if not os.path.exists(args.model_path):\n",
    "      os.makedirs(args.model_path) \n",
    "   args.result_path = args.result_path+'lambdaI'+str(args.lambda_I) +'/'\n",
    "   if not os.path.exists(args.result_path):\n",
    "      os.makedirs(args.result_path) \n",
    "   print ('------------------------Model and Training Details--------------------------')\n",
    "   print(args) \n",
    "   \n",
    "   for iter_ in range(iters):\n",
    "\n",
    "      \n",
    "      if args.data_type == 'sc': # should input a single cell resolution dataset, e.g. MERFISH\n",
    "         from CCST_merfish_utils import CCST_on_MERFISH\n",
    "         CCST_on_MERFISH(args)\n",
    "      elif args.data_type == 'nsc': # should input a non-single cell resolution dataset, e.g. V1_Breast_Cancer_Block_A_Section_1\n",
    "         from CCST_ST_utils import CCST_on_ST\n",
    "         preds = CCST_on_ST(args)\n",
    "      else:\n",
    "         print('Data type not specified')\n",
    "\n",
    "      # calculate metric ARI\n",
    "      obs_df = ad.obs.dropna()\n",
    "      ARI = adjusted_rand_score(np.array(preds)[:, 1], obs_df['original_clusters'].to_list())\n",
    "\n",
    "      print('Dataset:', dataset)\n",
    "      print('ARI:', ARI)\n",
    "      aris.append(ARI)\n",
    "   print('Dataset:', dataset)\n",
    "   print(aris)\n",
    "   print(np.mean(aris))\n",
    "   with open('ccst_aris.txt', 'a+') as fp:\n",
    "      fp.write('HBRC1 ')\n",
    "      fp.write(' '.join([str(i) for i in aris]))\n",
    "      fp.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"load MA section\"\"\"\n",
    "setting_combinations = [[52, 'MA']]\n",
    "for setting_combi in setting_combinations:\n",
    "   args.n_clusters = setting_combi[0]\n",
    "\n",
    "   args.data_name = setting_combi[1]\n",
    "   dataset = setting_combi[1]\n",
    "   args.data_type = 'nsc'\n",
    "   dir_ = './benchmarking_data/mMAMP'\n",
    "   ad = load_mMAMP(root_dir=dir_, section_id=args.data_name)\n",
    "   aris = []\n",
    "   args.embedding_data_path = args.embedding_data_path +'/'+ args.data_name +'/'\n",
    "   args.model_path = args.model_path +'/'+ args.data_name +'/'\n",
    "   args.result_path = args.result_path +'/'+ args.data_name +'/'\n",
    "   if not os.path.exists(args.embedding_data_path):\n",
    "      os.makedirs(args.embedding_data_path) \n",
    "   if not os.path.exists(args.model_path):\n",
    "      os.makedirs(args.model_path) \n",
    "   args.result_path = args.result_path+'lambdaI'+str(args.lambda_I) +'/'\n",
    "   if not os.path.exists(args.result_path):\n",
    "      os.makedirs(args.result_path) \n",
    "   print ('------------------------Model and Training Details--------------------------')\n",
    "   print(args) \n",
    "   \n",
    "   for iter_ in range(iters):\n",
    "\n",
    "      \n",
    "      if args.data_type == 'sc': # should input a single cell resolution dataset, e.g. MERFISH\n",
    "         from CCST_merfish_utils import CCST_on_MERFISH\n",
    "         CCST_on_MERFISH(args)\n",
    "      elif args.data_type == 'nsc': # should input a non-single cell resolution dataset, e.g. V1_Breast_Cancer_Block_A_Section_1\n",
    "         from CCST_ST_utils import CCST_on_ST\n",
    "         preds = CCST_on_ST(args)\n",
    "      else:\n",
    "         print('Data type not specified')\n",
    "\n",
    "      # calculate metric ARI\n",
    "      obs_df = ad.obs.dropna()\n",
    "      ARI = adjusted_rand_score(np.array(preds)[:, 1], obs_df['original_clusters'].to_list())\n",
    "\n",
    "      print('Dataset:', dataset)\n",
    "      print('ARI:', ARI)\n",
    "      aris.append(ARI)\n",
    "   print('Dataset:', dataset)\n",
    "   print(aris)\n",
    "   print(np.mean(aris))\n",
    "   with open('ccst_aris.txt', 'a+') as fp:\n",
    "      fp.write('mABC ')\n",
    "      fp.write(' '.join([str(i) for i in aris]))\n",
    "      fp.write('\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. mVC/mPFC datasets (4 slides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"mVC\"\"\"\n",
    "setting_combinations = [[7, 'STARmap_20180505_BY3_1k.h5ad']]\n",
    "for setting_combi in setting_combinations:\n",
    "   args.n_clusters = setting_combi[0]\n",
    "\n",
    "   args.data_name = setting_combi[1]\n",
    "   dataset = setting_combi[1]\n",
    "   args.data_type = 'nsc'\n",
    "   dir_ = './benchmarking_data/STARmap_mouse_visual_cortex'\n",
    "   ad = load_mVC(root_dir=dir_, section_id=args.data_name)\n",
    "   aris = []\n",
    "   args.embedding_data_path = args.embedding_data_path +'/'+ args.data_name +'/'\n",
    "   args.model_path = args.model_path +'/'+ args.data_name +'/'\n",
    "   args.result_path = args.result_path +'/'+ args.data_name +'/'\n",
    "   if not os.path.exists(args.embedding_data_path):\n",
    "      os.makedirs(args.embedding_data_path) \n",
    "   if not os.path.exists(args.model_path):\n",
    "      os.makedirs(args.model_path) \n",
    "   args.result_path = args.result_path+'lambdaI'+str(args.lambda_I) +'/'\n",
    "   if not os.path.exists(args.result_path):\n",
    "      os.makedirs(args.result_path) \n",
    "   print ('------------------------Model and Training Details--------------------------')\n",
    "   print(args) \n",
    "   \n",
    "   for iter_ in range(iters):\n",
    "\n",
    "      \n",
    "      if args.data_type == 'sc': # should input a single cell resolution dataset, e.g. MERFISH\n",
    "         from CCST_merfish_utils import CCST_on_MERFISH\n",
    "         CCST_on_MERFISH(args)\n",
    "      elif args.data_type == 'nsc': # should input a non-single cell resolution dataset, e.g. V1_Breast_Cancer_Block_A_Section_1\n",
    "         from CCST_ST_utils import CCST_on_ST\n",
    "         preds = CCST_on_ST(args)\n",
    "      else:\n",
    "         print('Data type not specified')\n",
    "\n",
    "      # calculate metric ARI\n",
    "      obs_df = ad.obs.dropna()\n",
    "      ARI = adjusted_rand_score(np.array(preds)[:, 1], obs_df['original_clusters'].to_list())\n",
    "\n",
    "      print('Dataset:', dataset)\n",
    "      print('ARI:', ARI)\n",
    "      aris.append(ARI)\n",
    "   print('Dataset:', dataset)\n",
    "   print(aris)\n",
    "   print(np.mean(aris))\n",
    "   with open('ccst_aris.txt', 'a+') as fp:\n",
    "      fp.write('mVC ')\n",
    "      fp.write(' '.join([str(i) for i in aris]))\n",
    "      fp.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"mPFC\"\"\"\n",
    "setting_combinations = [[4, '20180417_BZ5_control'], [4, '20180419_BZ9_control'], [4, '20180424_BZ14_control']]\n",
    "for setting_combi in setting_combinations:\n",
    "   args.n_clusters = setting_combi[0]\n",
    "\n",
    "   args.data_name = setting_combi[1]\n",
    "   dataset = setting_combi[1]\n",
    "   args.data_type = 'nsc'\n",
    "   dir_ = './benchmarking_data/STARmap_mouse_PFC'\n",
    "   ad = load_mPFC(root_dir=dir_, section_id=args.data_name)\n",
    "   aris = []\n",
    "   args.embedding_data_path = args.embedding_data_path +'/'+ args.data_name +'/'\n",
    "   args.model_path = args.model_path +'/'+ args.data_name +'/'\n",
    "   args.result_path = args.result_path +'/'+ args.data_name +'/'\n",
    "   if not os.path.exists(args.embedding_data_path):\n",
    "      os.makedirs(args.embedding_data_path) \n",
    "   if not os.path.exists(args.model_path):\n",
    "      os.makedirs(args.model_path) \n",
    "   args.result_path = args.result_path+'lambdaI'+str(args.lambda_I) +'/'\n",
    "   if not os.path.exists(args.result_path):\n",
    "      os.makedirs(args.result_path) \n",
    "   print ('------------------------Model and Training Details--------------------------')\n",
    "   print(args) \n",
    "   \n",
    "   for iter_ in range(iters):\n",
    "\n",
    "      \n",
    "      if args.data_type == 'sc': # should input a single cell resolution dataset, e.g. MERFISH\n",
    "         from CCST_merfish_utils import CCST_on_MERFISH\n",
    "         CCST_on_MERFISH(args)\n",
    "      elif args.data_type == 'nsc': # should input a non-single cell resolution dataset, e.g. V1_Breast_Cancer_Block_A_Section_1\n",
    "         from CCST_ST_utils import CCST_on_ST\n",
    "         preds = CCST_on_ST(args)\n",
    "      else:\n",
    "         print('Data type not specified')\n",
    "\n",
    "      # calculate metric ARI\n",
    "      obs_df = ad.obs.dropna()\n",
    "      ARI = adjusted_rand_score(np.array(preds)[:, 1], obs_df['original_clusters'].to_list())\n",
    "\n",
    "      print('Dataset:', dataset)\n",
    "      print('ARI:', ARI)\n",
    "      aris.append(ARI)\n",
    "   print('Dataset:', dataset)\n",
    "   print(aris)\n",
    "   print(np.mean(aris))\n",
    "   with open('ccst_aris.txt', 'a+') as fp:\n",
    "      fp.write('mPFC' + dataset + ' ')\n",
    "      fp.write(' '.join([str(i) for i in aris]))\n",
    "      fp.write('\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. mHypothalamus dataset (6 slides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"mHypo\"\"\"\n",
    "setting_combinations = [[8, '-0.14'], [8, '-0.19'], [8, '-0.24'], [8, '-0.29']]\n",
    "for setting_combi in setting_combinations:\n",
    "   args.n_clusters = setting_combi[0]\n",
    "\n",
    "   args.data_name = setting_combi[1]\n",
    "   dataset = setting_combi[1]\n",
    "   args.data_type = 'nsc'\n",
    "   dir_ = './benchmarking_data/mHypothalamus'\n",
    "   ad = load_mHypothalamus(root_dir=dir_, section_id=args.data_name)\n",
    "   aris = []\n",
    "   args.embedding_data_path = args.embedding_data_path +'/'+ args.data_name +'/'\n",
    "   args.model_path = args.model_path +'/'+ args.data_name +'/'\n",
    "   args.result_path = args.result_path +'/'+ args.data_name +'/'\n",
    "   if not os.path.exists(args.embedding_data_path):\n",
    "      os.makedirs(args.embedding_data_path) \n",
    "   if not os.path.exists(args.model_path):\n",
    "      os.makedirs(args.model_path) \n",
    "   args.result_path = args.result_path+'lambdaI'+str(args.lambda_I) +'/'\n",
    "   if not os.path.exists(args.result_path):\n",
    "      os.makedirs(args.result_path) \n",
    "   print ('------------------------Model and Training Details--------------------------')\n",
    "   print(args) \n",
    "   \n",
    "   for iter_ in range(iters):\n",
    "\n",
    "      \n",
    "      if args.data_type == 'sc': # should input a single cell resolution dataset, e.g. MERFISH\n",
    "         from CCST_merfish_utils import CCST_on_MERFISH\n",
    "         CCST_on_MERFISH(args)\n",
    "      elif args.data_type == 'nsc': # should input a non-single cell resolution dataset, e.g. V1_Breast_Cancer_Block_A_Section_1\n",
    "         from CCST_ST_utils import CCST_on_ST\n",
    "         preds = CCST_on_ST(args)\n",
    "      else:\n",
    "         print('Data type not specified')\n",
    "\n",
    "      # calculate metric ARI\n",
    "      # obs_df = ad.obs\n",
    "      # print(obs_df)\n",
    "      # print(np.array(preds).shape)\n",
    "      ARI = adjusted_rand_score(np.array(preds)[:, 1], ad.obs['original_clusters'].to_list())\n",
    "      # exit(-1)\n",
    "      print('Dataset:', dataset)\n",
    "      print('ARI:', ARI)\n",
    "      aris.append(ARI)\n",
    "   print('Dataset:', dataset)\n",
    "   print(aris)\n",
    "   print(np.mean(aris))\n",
    "   with open('ccst_aris.txt', 'a+') as fp:\n",
    "      fp.write('mHypothalamus' + dataset + ' ')\n",
    "      fp.write(' '.join([str(i) for i in aris]))\n",
    "      fp.write('\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Her2Tumor dataset (8 slides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Her2\"\"\"\n",
    "setting_combinations = [[6, 'A1'], [5, 'B1'], [4, 'C1'], [4, 'D1'], [4, 'E1'], [4, 'F1'], [7, 'G2'], [7, 'H1']]\n",
    "for setting_combi in setting_combinations:\n",
    "   args.n_clusters = setting_combi[0]\n",
    "\n",
    "   args.data_name = setting_combi[1]\n",
    "   dataset = setting_combi[1]\n",
    "   args.data_type = 'nsc'\n",
    "   dir_ = './benchmarking_data/Her2_tumor'\n",
    "   ad = load_her2_tumor(root_dir=dir_, section_id=args.data_name)\n",
    "   aris = []\n",
    "   args.embedding_data_path = args.embedding_data_path +'/'+ args.data_name +'/'\n",
    "   args.model_path = args.model_path +'/'+ args.data_name +'/'\n",
    "   args.result_path = args.result_path +'/'+ args.data_name +'/'\n",
    "   if not os.path.exists(args.embedding_data_path):\n",
    "      os.makedirs(args.embedding_data_path) \n",
    "   if not os.path.exists(args.model_path):\n",
    "      os.makedirs(args.model_path) \n",
    "   args.result_path = args.result_path+'lambdaI'+str(args.lambda_I) +'/'\n",
    "   if not os.path.exists(args.result_path):\n",
    "      os.makedirs(args.result_path) \n",
    "   print ('------------------------Model and Training Details--------------------------')\n",
    "   print(args) \n",
    "   \n",
    "   for iter_ in range(iters):\n",
    "\n",
    "      \n",
    "      if args.data_type == 'sc': # should input a single cell resolution dataset, e.g. MERFISH\n",
    "         from CCST_merfish_utils import CCST_on_MERFISH\n",
    "         CCST_on_MERFISH(args)\n",
    "      elif args.data_type == 'nsc': # should input a non-single cell resolution dataset, e.g. V1_Breast_Cancer_Block_A_Section_1\n",
    "         from CCST_ST_utils import CCST_on_ST\n",
    "         preds = CCST_on_ST(args)\n",
    "      else:\n",
    "         print('Data type not specified')\n",
    "\n",
    "      # calculate metric ARI\n",
    "      obs_df = ad.obs.dropna()\n",
    "      ARI = adjusted_rand_score(np.array(preds)[:, 1], obs_df['original_clusters'].to_list())\n",
    "\n",
    "      print('Dataset:', dataset)\n",
    "      print('ARI:', ARI)\n",
    "      aris.append(ARI)\n",
    "   print('Dataset:', dataset)\n",
    "   print(aris)\n",
    "   print(np.mean(aris))\n",
    "   with open('ccst_aris.txt', 'a+') as fp:\n",
    "      fp.write('Her2tumor' + dataset + ' ')\n",
    "      fp.write(' '.join([str(i) for i in aris]))\n",
    "      fp.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
