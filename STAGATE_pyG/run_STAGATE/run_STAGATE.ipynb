{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. import packages and select GPU if accessible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "import STAGATE_pyG as STAGATE\n",
    "import torch\n",
    "from st_loading_utils import load_DLPFC, load_BC, load_mVC, load_mPFC, load_mHypothalamus, load_her2_tumor, load_mMAMP\n",
    "\n",
    "# Run device, by default, the package is implemented on 'cpu'. We recommend using GPU.\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "iters = 1 # for script testing\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. DLPFC dataset (12 slides)\n",
    "\n",
    "change '${dir_}' to  'path/to/your/DLPFC/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"DLPFC\"\"\"\n",
    "setting_combinations = [[7, '151507'], [7, '151508'], [7, '151509'], [7, '151510'], [5, '151669'], [5, '151670'], [5, '151671'], [5, '151672'], [7, '151673'], [7, '151674'], [7, '151675'], [7, '151676']]\n",
    "for setting_combi in setting_combinations:\n",
    "   n_clusters = setting_combi[0]  # 7\n",
    "\n",
    "   dataset = setting_combi[1]  # '151673'\n",
    "   \n",
    "   dir_ = './benchmarking_data/DLPFC12'\n",
    "   ad = load_DLPFC(root_dir=dir_, section_id=dataset)\n",
    "\n",
    "   aris = []\n",
    "   sc.pp.highly_variable_genes(ad, flavor=\"seurat_v3\", n_top_genes=3000)\n",
    "   sc.pp.normalize_total(ad, target_sum=1e4)\n",
    "   sc.pp.log1p(ad)\n",
    "\n",
    "   STAGATE.Cal_Spatial_Net(ad, rad_cutoff=150)\n",
    "   STAGATE.Stats_Spatial_Net(ad)\n",
    "   for iter in range(iters):\n",
    "\n",
    "      \n",
    "      ad = STAGATE.train_STAGATE(ad)\n",
    "      sc.pp.neighbors(ad, use_rep='STAGATE')\n",
    "      sc.tl.umap(ad)\n",
    "      ad = STAGATE.mclust_R(ad, used_obsm='STAGATE', num_cluster=n_clusters)\n",
    "\n",
    "      # calculate metric ARI\n",
    "      obs_df = ad.obs.dropna()\n",
    "      ARI = adjusted_rand_score(obs_df['mclust'], obs_df['original_clusters'])\n",
    "\n",
    "      print('Dataset:', dataset)\n",
    "      print('ARI:', ARI)\n",
    "      aris.append(ARI)\n",
    "   print('Dataset:', dataset)\n",
    "   print(aris)\n",
    "   print(np.mean(aris))\n",
    "   with open('stagate_aris.txt', 'a+') as fp:\n",
    "      fp.write('DLPFC' + dataset + ' ')\n",
    "      fp.write(' '.join([str(i) for i in aris]))\n",
    "      fp.write('\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. BC/MA datasets (2 slides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"BC\"\"\"\n",
    "setting_combinations = [[20, 'section1']]\n",
    "for setting_combi in setting_combinations:\n",
    "   n_clusters = setting_combi[0]  # 7\n",
    "\n",
    "   dataset = setting_combi[1]  #\n",
    "   \n",
    "   dir_ = './benchmarking_data/BC'\n",
    "   adata = load_BC(root_dir=dir_, section_id=dataset)\n",
    "\n",
    "   aris = []\n",
    "   sc.pp.highly_variable_genes(adata, flavor=\"seurat_v3\", n_top_genes=3000)\n",
    "   sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "   sc.pp.log1p(adata)\n",
    "\n",
    "   STAGATE.Cal_Spatial_Net(adata, rad_cutoff=150)\n",
    "   STAGATE.Stats_Spatial_Net(adata)\n",
    "   for iter in range(iters):\n",
    "\n",
    "      \n",
    "      adata = STAGATE.train_STAGATE(adata)\n",
    "      sc.pp.neighbors(adata, use_rep='STAGATE')\n",
    "      sc.tl.umap(adata)\n",
    "      adata = STAGATE.mclust_R(adata, used_obsm='STAGATE', num_cluster=n_clusters)\n",
    "\n",
    "      # calculate metric ARI\n",
    "      obs_df = adata.obs.dropna()\n",
    "      ARI = adjusted_rand_score(obs_df['mclust'], obs_df['original_clusters'])\n",
    "\n",
    "      print('Dataset:', dataset)\n",
    "      print('ARI:', ARI)\n",
    "      aris.append(ARI)\n",
    "   print('Dataset:', dataset)\n",
    "   print(aris)\n",
    "   print(np.mean(aris))\n",
    "   with open('stagate_aris.txt', 'a+') as fp:\n",
    "      fp.write('HBRC1 ')\n",
    "      fp.write(' '.join([str(i) for i in aris]))\n",
    "      fp.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"load MA section\"\"\"\n",
    "setting_combinations = [[52, 'MA']]\n",
    "for setting_combi in setting_combinations:\n",
    "   n_clusters = setting_combi[0] \n",
    "\n",
    "   dataset = setting_combi[1]\n",
    "   \n",
    "   dir_ = './benchmarking_data/mMAMP'\n",
    "   adata = load_mMAMP(root_dir=dir_, section_id=dataset)\n",
    "\n",
    "   aris = []\n",
    "   sc.pp.highly_variable_genes(adata, flavor=\"seurat_v3\", n_top_genes=3000)\n",
    "   sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "   sc.pp.log1p(adata)\n",
    "\n",
    "   STAGATE.Cal_Spatial_Net(adata, rad_cutoff=150)\n",
    "   STAGATE.Stats_Spatial_Net(adata)\n",
    "   for iter in range(iters):\n",
    "\n",
    "      \n",
    "      adata = STAGATE.train_STAGATE(adata)\n",
    "      sc.pp.neighbors(adata, use_rep='STAGATE')\n",
    "      sc.tl.umap(adata)\n",
    "      adata = STAGATE.mclust_R(adata, used_obsm='STAGATE', num_cluster=n_clusters)\n",
    "\n",
    "      # calculate metric ARI\n",
    "      obs_df = adata.obs.dropna()\n",
    "      ARI = adjusted_rand_score(obs_df['mclust'], obs_df['original_clusters'])\n",
    "\n",
    "      print('Dataset:', dataset)\n",
    "      print('ARI:', ARI)\n",
    "      aris.append(ARI)\n",
    "   print('Dataset:', dataset)\n",
    "   print(aris)\n",
    "   print(np.mean(aris))\n",
    "   with open('stagate_aris.txt', 'a+') as fp:\n",
    "      fp.write('mABC ')\n",
    "      fp.write(' '.join([str(i) for i in aris]))\n",
    "      fp.write('\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. mVC/mPFC datasets (4 slides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"mVC\"\"\"\n",
    "setting_combinations = [[7, 'STARmap_20180505_BY3_1k.h5ad']]\n",
    "for setting_combi in setting_combinations:\n",
    "   n_clusters = setting_combi[0]\n",
    "\n",
    "   dataset = setting_combi[1]\n",
    "   \n",
    "   dir_ = './benchmarking_data/STARmap_mouse_visual_cortex'\n",
    "   adata = load_mVC(root_dir=dir_, section_id=dataset)\n",
    "\n",
    "   aris = []\n",
    "   sc.pp.highly_variable_genes(adata, flavor=\"seurat_v3\", n_top_genes=3000)\n",
    "   sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "   sc.pp.log1p(adata)\n",
    "\n",
    "   STAGATE.Cal_Spatial_Net(adata, rad_cutoff=150)\n",
    "   STAGATE.Stats_Spatial_Net(adata)\n",
    "   for iter in range(iters):\n",
    "\n",
    "      \n",
    "      adata = STAGATE.train_STAGATE(adata)\n",
    "      sc.pp.neighbors(adata, use_rep='STAGATE')\n",
    "      sc.tl.umap(adata)\n",
    "      adata = STAGATE.mclust_R(adata, used_obsm='STAGATE', num_cluster=n_clusters)\n",
    "\n",
    "      # calculate metric ARI\n",
    "      obs_df = adata.obs.dropna()\n",
    "      ARI = adjusted_rand_score(obs_df['mclust'], obs_df['original_clusters'])\n",
    "\n",
    "      print('Dataset:', dataset)\n",
    "      print('ARI:', ARI)\n",
    "      aris.append(ARI)\n",
    "   print('Dataset:', dataset)\n",
    "   print(aris)\n",
    "   print(np.mean(aris))\n",
    "   with open('stagate_aris.txt', 'a+') as fp:\n",
    "      fp.write('mVC ')\n",
    "      fp.write(' '.join([str(i) for i in aris]))\n",
    "      fp.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"mPFC\"\"\"\n",
    "setting_combinations = [[4, '20180417_BZ5_control'], [4, '20180419_BZ9_control'], [4, '20180424_BZ14_control']]\n",
    "for setting_combi in setting_combinations:\n",
    "   n_clusters = setting_combi[0]\n",
    "\n",
    "   dataset = setting_combi[1]\n",
    "   \n",
    "   dir_ = './benchmarking_data/STARmap_mouse_PFC'\n",
    "   adata = load_mPFC(root_dir=dir_, section_id=dataset)\n",
    "\n",
    "   aris = []\n",
    "   sc.pp.highly_variable_genes(adata, flavor=\"seurat_v3\", n_top_genes=3000)\n",
    "   sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "   sc.pp.log1p(adata)\n",
    "\n",
    "   STAGATE.Cal_Spatial_Net(adata, rad_cutoff=150)\n",
    "   STAGATE.Stats_Spatial_Net(adata)\n",
    "   for iter in range(iters):\n",
    "\n",
    "      \n",
    "      adata = STAGATE.train_STAGATE(adata)\n",
    "      sc.pp.neighbors(adata, use_rep='STAGATE')\n",
    "      sc.tl.umap(adata)\n",
    "      adata = STAGATE.mclust_R(adata, used_obsm='STAGATE', num_cluster=n_clusters)\n",
    "\n",
    "      # calculate metric ARI\n",
    "      obs_df = adata.obs.dropna()\n",
    "      ARI = adjusted_rand_score(obs_df['mclust'], obs_df['original_clusters'])\n",
    "\n",
    "      print('Dataset:', dataset)\n",
    "      print('ARI:', ARI)\n",
    "      aris.append(ARI)\n",
    "   print('Dataset:', dataset)\n",
    "   print(aris)\n",
    "   print(np.mean(aris))\n",
    "   with open('stagate_aris.txt', 'a+') as fp:\n",
    "      fp.write('mPFC' + dataset + ' ')\n",
    "      fp.write(' '.join([str(i) for i in aris]))\n",
    "      fp.write('\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. mHypothalamus dataset (6 slides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './benchmarking_data/mHypothalamus/MERFISH_Animal1_cnts.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_761477/862136739.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m    \u001b[0mdir_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./benchmarking_data/mHypothalamus'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m    \u001b[0madata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_mHypothalamus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdir_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msection_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m    \u001b[0maris\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spatial_benchmarking/BenchmarkST/STAGATE_pyG/run_STAGATE/st_loading_utils.py\u001b[0m in \u001b[0;36mload_mHypothalamus\u001b[0;34m(root_dir, section_id)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0minfo_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'MERFISH_Animal1_info.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0mcnts_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'MERFISH_Animal1_cnts.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0mxls_cnts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnts_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;31m# print(xls_cnts.sheet_names)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mdf_cnts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxls_cnts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msection_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/test/lib/python3.7/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[1;32m   1079\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m                 ext = inspect_excel_format(\n\u001b[0;32m-> 1081\u001b[0;31m                     \u001b[0mcontent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m                 )\n\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/test/lib/python3.7/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(path, content, storage_options)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m     with get_handle(\n\u001b[0;32m--> 959\u001b[0;31m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    960\u001b[0m     ) as handle:\n\u001b[1;32m    961\u001b[0m         \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/test/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 656\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    657\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './benchmarking_data/mHypothalamus/MERFISH_Animal1_cnts.xlsx'"
     ]
    }
   ],
   "source": [
    "\"\"\"mHypo\"\"\"\n",
    "setting_combinations = [[8, '-0.04'], [8, '-0.09'], [8, '-0.14'], [8, '-0.19'], [8, '-0.24'], [8, '-0.29']]\n",
    "for setting_combi in setting_combinations:\n",
    "   n_clusters = setting_combi[0]\n",
    "\n",
    "   dataset = setting_combi[1]\n",
    "   \n",
    "   dir_ = '/home/yunfei/spatial_benchmarking/benchmarking_data/mHypothalamus'\n",
    "   adata = load_mHypothalamus(root_dir=dir_, section_id=dataset)\n",
    "\n",
    "   aris = []\n",
    "   sc.pp.highly_variable_genes(adata, flavor=\"seurat_v3\", n_top_genes=3000)\n",
    "   sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "   sc.pp.log1p(adata)\n",
    "\n",
    "   STAGATE.Cal_Spatial_Net(adata, rad_cutoff=150)\n",
    "   STAGATE.Stats_Spatial_Net(adata)\n",
    "   for iter in range(iters):\n",
    "\n",
    "      \n",
    "      adata = STAGATE.train_STAGATE(adata)\n",
    "      sc.pp.neighbors(adata, use_rep='STAGATE')\n",
    "      sc.tl.umap(adata)\n",
    "      adata = STAGATE.mclust_R(adata, used_obsm='STAGATE', num_cluster=n_clusters)\n",
    "\n",
    "      # calculate metric ARI\n",
    "      obs_df = adata.obs.dropna()\n",
    "      ARI = adjusted_rand_score(obs_df['mclust'], obs_df['original_clusters'])\n",
    "\n",
    "      print('Dataset:', dataset)\n",
    "      print('ARI:', ARI)\n",
    "      aris.append(ARI)\n",
    "   print('Dataset:', dataset)\n",
    "   print(aris)\n",
    "   print(np.mean(aris))\n",
    "   with open('stagate_aris.txt', 'a+') as fp:\n",
    "      fp.write('mHypothalamus' + dataset + ' ')\n",
    "      fp.write(' '.join([str(i) for i in aris]))\n",
    "      fp.write('\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Her2Tumor dataset (8 slides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Her2\"\"\"\n",
    "setting_combinations = [[6, 'A1'], [5, 'B1'], [4, 'C1'], [4, 'D1'], [4, 'E1'], [4, 'F1'], [7, 'G2'], [7, 'H1']]\n",
    "for setting_combi in setting_combinations:\n",
    "   n_clusters = setting_combi[0]\n",
    "\n",
    "   dataset = setting_combi[1]\n",
    "   \n",
    "   dir_ = './benchmarking_data/Her2_tumor'\n",
    "   adata = load_her2_tumor(root_dir=dir_, section_id=dataset)\n",
    "\n",
    "   aris = []\n",
    "   sc.pp.highly_variable_genes(adata, flavor=\"seurat_v3\", n_top_genes=3000)\n",
    "   sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "   sc.pp.log1p(adata)\n",
    "\n",
    "   STAGATE.Cal_Spatial_Net(adata, rad_cutoff=150)\n",
    "   STAGATE.Stats_Spatial_Net(adata)\n",
    "   for iter in range(iters):\n",
    "\n",
    "      \n",
    "      adata = STAGATE.train_STAGATE(adata)\n",
    "      sc.pp.neighbors(adata, use_rep='STAGATE')\n",
    "      sc.tl.umap(adata)\n",
    "      adata = STAGATE.mclust_R(adata, used_obsm='STAGATE', num_cluster=n_clusters)\n",
    "\n",
    "      # calculate metric ARI\n",
    "      obs_df = adata.obs.dropna()\n",
    "      ARI = adjusted_rand_score(obs_df['mclust'], obs_df['original_clusters'])\n",
    "\n",
    "      print('Dataset:', dataset)\n",
    "      print('ARI:', ARI)\n",
    "      aris.append(ARI)\n",
    "   print('Dataset:', dataset)\n",
    "   print(aris)\n",
    "   print(np.mean(aris))\n",
    "   with open('stagate_aris.txt', 'a+') as fp:\n",
    "      fp.write('Her2tumor' + dataset + ' ')\n",
    "      fp.write(' '.join([str(i) for i in aris]))\n",
    "      fp.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
