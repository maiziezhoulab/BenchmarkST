{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. import packages and select GPU if accessible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "from sklearn import metrics\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "from GraphST import GraphST\n",
    "from GraphST.utils import clustering\n",
    "from st_loading_utils import load_DLPFC, load_BC, load_mVC, load_mPFC, load_mHypothalamus, load_her2_tumor, load_mMAMP\n",
    "\n",
    "# Run device, by default, the package is implemented on 'cpu'. We recommend using GPU.\n",
    "device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. DLPFC dataset (12 slides)\n",
    "\n",
    "change '${dir_}' to  'path/to/your/DLPFC/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"DLPFC\"\"\"\n",
    "setting_combinations = [[7, '151507'], [7, '151508'], [7, '151509'], [7, '151510'], [5, '151669'], [5, '151670'], [5, '151671'], [5, '151672'], [7, '151673'], [7, '151674'], [7, '151675'], [7, '151676']]\n",
    "\n",
    "for setting_combi in setting_combinations:\n",
    "   n_clusters = setting_combi[0]  # 7\n",
    "\n",
    "   dataset = setting_combi[1]  # '151673'\n",
    "   \n",
    "   dir_ = './benchmarking_data/DLPFC12'\n",
    "   ad = load_DLPFC(root_dir=dir_, section_id=dataset)\n",
    "\n",
    "   aris = []\n",
    "   for iter in range(20):\n",
    "\n",
    "      \n",
    "      # print(ad)\n",
    "\n",
    "      # define model\n",
    "      model = GraphST.GraphST(ad, device=device)\n",
    "\n",
    "      # train model\n",
    "      ad = model.train()\n",
    "\n",
    "      # print(ad)\n",
    "\n",
    "      # set radius to specify the number of neighbors considered during refinement\n",
    "      radius = 50\n",
    "\n",
    "      tool = 'mclust' # mclust, leiden, and louvain\n",
    "\n",
    "      # clustering\n",
    "      if tool == 'mclust':\n",
    "         clustering(ad, n_clusters, radius=radius, method=tool, refinement=True) # For DLPFC dataset, we use optional refinement step.\n",
    "      elif tool in ['leiden', 'louvain']:\n",
    "         clustering(ad, n_clusters, radius=radius, method=tool, start=0.1, end=2.0, increment=0.01, refinement=False)\n",
    "\n",
    "      # filter out NA nodes\n",
    "      ad = ad[~pd.isnull(ad.obs['original_clusters'])]\n",
    "\n",
    "      # calculate metric ARI\n",
    "      ARI = metrics.adjusted_rand_score(ad.obs['domain'], ad.obs['original_clusters'])\n",
    "      ad.uns['ARI'] = ARI\n",
    "\n",
    "      print('Dataset:', dataset)\n",
    "      print('ARI:', ARI)\n",
    "      aris.append(ARI)\n",
    "   print('Dataset:', dataset)\n",
    "   print(aris)\n",
    "   print(np.mean(aris))\n",
    "   with open('graphst_aris.txt', 'a+') as fp:\n",
    "      fp.write('DLPFC' + dataset + ' ')\n",
    "      fp.write(' '.join([str(i) for i in aris]))\n",
    "      fp.write('\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. BC/MA datasets (2 slides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"BC\"\"\"\n",
    "# the number of clusters\n",
    "setting_combinations = [[20, 'section1']]\n",
    "for setting_combi in setting_combinations:\n",
    "   n_clusters = setting_combi[0]\n",
    "\n",
    "   dataset = setting_combi[1]\n",
    "   \n",
    "   dir_ = './benchmarking_data/BC'\n",
    "   ad = load_BC(root_dir=dir_, section_id=dataset)\n",
    "\n",
    "   aris = []\n",
    "   for iter in range(5):\n",
    "\n",
    "      \n",
    "      # print(ad)\n",
    "\n",
    "      # define model\n",
    "      model = GraphST.GraphST(ad, device=device)\n",
    "\n",
    "      # train model\n",
    "      ad = model.train()\n",
    "\n",
    "      # print(ad)\n",
    "\n",
    "      # set radius to specify the number of neighbors considered during refinement\n",
    "      radius = 50\n",
    "\n",
    "      tool = 'mclust' # mclust, leiden, and louvain\n",
    "\n",
    "      # clustering\n",
    "      if tool == 'mclust':\n",
    "         clustering(ad, n_clusters, radius=radius, method=tool, refinement=True) # For DLPFC dataset, we use optional refinement step.\n",
    "      elif tool in ['leiden', 'louvain']:\n",
    "         clustering(ad, n_clusters, radius=radius, method=tool, start=0.1, end=2.0, increment=0.01, refinement=False)\n",
    "\n",
    "      # filter out NA nodes\n",
    "      ad = ad[~pd.isnull(ad.obs['original_clusters'])]\n",
    "\n",
    "      # calculate metric ARI\n",
    "      ARI = metrics.adjusted_rand_score(ad.obs['domain'], ad.obs['original_clusters'])\n",
    "      ad.uns['ARI'] = ARI\n",
    "\n",
    "      # print('Dataset:', dataset)\n",
    "      # print('ARI:', ARI)\n",
    "      aris.append(ARI)\n",
    "   print('Dataset:', dataset)\n",
    "   print(aris)\n",
    "   print(np.mean(aris))\n",
    "   with open('graphst_aris.txt', 'a+') as fp:\n",
    "      fp.write('HBRC1 ')\n",
    "      fp.write(' '.join([str(i) for i in aris]))\n",
    "      fp.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"load mouse anterior brain section\"\"\"\n",
    "setting_combinations = [[52, 'MA']]\n",
    "for setting_combi in setting_combinations:\n",
    "   n_clusters = setting_combi[0]\n",
    "\n",
    "   dataset = setting_combi[1]\n",
    "   \n",
    "   dir_ = './benchmarking_data/mMAMP'\n",
    "   ad = load_mMAMP(root_dir=dir_, section_id=dataset)\n",
    "\n",
    "   aris = []\n",
    "   for iter in range(5):\n",
    "\n",
    "      # define model\n",
    "      model = GraphST.GraphST(ad, device=device)\n",
    "\n",
    "      # train model\n",
    "      ad = model.train()\n",
    "\n",
    "      # print(ad)\n",
    "\n",
    "      # set radius to specify the number of neighbors considered during refinement\n",
    "      radius = 50\n",
    "\n",
    "      tool = 'mclust' # mclust, leiden, and louvain\n",
    "\n",
    "      # clustering\n",
    "      if tool == 'mclust':\n",
    "         clustering(ad, n_clusters, radius=radius, method=tool, refinement=True) # For DLPFC dataset, we use optional refinement step.\n",
    "      elif tool in ['leiden', 'louvain']:\n",
    "         clustering(ad, n_clusters, radius=radius, method=tool, start=0.1, end=2.0, increment=0.01, refinement=False)\n",
    "\n",
    "      # filter out NA nodes\n",
    "      ad = ad[~pd.isnull(ad.obs['original_clusters'])]\n",
    "\n",
    "      # calculate metric ARI\n",
    "      ARI = metrics.adjusted_rand_score(ad.obs['domain'], ad.obs['original_clusters'])\n",
    "      ad.uns['ARI'] = ARI\n",
    "\n",
    "      # print('Dataset:', dataset)\n",
    "      # print('ARI:', ARI)\n",
    "      aris.append(ARI)\n",
    "   print('Dataset:', dataset)\n",
    "   print(aris)\n",
    "   print(np.mean(aris))\n",
    "   with open('graphst_aris.txt', 'a+') as fp:\n",
    "      fp.write('mAB' + dataset + ' ')\n",
    "      fp.write(' '.join([str(i) for i in aris]))\n",
    "      fp.write('\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. mVC/mPFC datasets (4 slides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"mVC\"\"\"\n",
    "setting_combinations = [[7, 'STARmap_20180505_BY3_1k.h5ad']]\n",
    "for setting_combi in setting_combinations:\n",
    "   n_clusters = setting_combi[0]\n",
    "\n",
    "   dataset = setting_combi[1]\n",
    "   \n",
    "   dir_ = './benchmarking_data/STARmap_mouse_visual_cortex'\n",
    "   ad = load_mVC(root_dir=dir_, section_id=dataset)\n",
    "\n",
    "   aris = []\n",
    "   for iter in range(5):\n",
    "\n",
    "      model = GraphST.GraphST(ad, device=device)\n",
    "\n",
    "      # train model\n",
    "      ad = model.train()\n",
    "\n",
    "      # print(ad)\n",
    "\n",
    "      # set radius to specify the number of neighbors considered during refinement\n",
    "      radius = 50\n",
    "\n",
    "      tool = 'mclust' # mclust, leiden, and louvain\n",
    "\n",
    "      # clustering\n",
    "      if tool == 'mclust':\n",
    "         clustering(ad, n_clusters, radius=radius, method=tool, refinement=True) # For DLPFC dataset, we use optional refinement step.\n",
    "      elif tool in ['leiden', 'louvain']:\n",
    "         clustering(ad, n_clusters, radius=radius, method=tool, start=0.1, end=2.0, increment=0.01, refinement=False)\n",
    "\n",
    "      # filter out NA nodes\n",
    "      ad = ad[~pd.isnull(ad.obs['original_clusters'])]\n",
    "\n",
    "      # calculate metric ARI\n",
    "      ARI = metrics.adjusted_rand_score(ad.obs['domain'], ad.obs['original_clusters'])\n",
    "      ad.uns['ARI'] = ARI\n",
    "\n",
    "      # print('Dataset:', dataset)\n",
    "      # print('ARI:', ARI)\n",
    "      aris.append(ARI)\n",
    "   print('Dataset:', dataset)\n",
    "   print(aris)\n",
    "   print(np.mean(aris))\n",
    "   with open('graphst_aris.txt', 'a+') as fp:\n",
    "      fp.write('mVC ')\n",
    "      fp.write(' '.join([str(i) for i in aris]))\n",
    "      fp.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"mPFC\"\"\"\n",
    "setting_combinations = [[4, '20180417_BZ5_control'], [4, '20180419_BZ9_control'], [4, '20180424_BZ14_control']]\n",
    "for setting_combi in setting_combinations:\n",
    "   n_clusters = setting_combi[0]\n",
    "\n",
    "   dataset = setting_combi[1]\n",
    "   \n",
    "   dir_ = './benchmarking_data/STARmap_mouse_PFC'\n",
    "   ad = load_mPFC(root_dir=dir_, section_id=dataset)\n",
    "\n",
    "   aris = []\n",
    "   for iter in range(5):\n",
    "\n",
    "      \n",
    "      # print(ad)\n",
    "\n",
    "      # define model\n",
    "      model = GraphST.GraphST(ad, device=device)\n",
    "\n",
    "      # train model\n",
    "      ad = model.train()\n",
    "\n",
    "      # print(ad)\n",
    "\n",
    "      # set radius to specify the number of neighbors considered during refinement\n",
    "      radius = 50\n",
    "\n",
    "      tool = 'mclust' # mclust, leiden, and louvain\n",
    "\n",
    "      # clustering\n",
    "      if tool == 'mclust':\n",
    "         clustering(ad, n_clusters, radius=radius, method=tool, refinement=True) # For DLPFC dataset, we use optional refinement step.\n",
    "      elif tool in ['leiden', 'louvain']:\n",
    "         clustering(ad, n_clusters, radius=radius, method=tool, start=0.1, end=2.0, increment=0.01, refinement=False)\n",
    "\n",
    "      # filter out NA nodes\n",
    "      ad = ad[~pd.isnull(ad.obs['original_clusters'])]\n",
    "\n",
    "      # calculate metric ARI\n",
    "      ARI = metrics.adjusted_rand_score(ad.obs['domain'], ad.obs['original_clusters'])\n",
    "      ad.uns['ARI'] = ARI\n",
    "\n",
    "      # print('Dataset:', dataset)\n",
    "      # print('ARI:', ARI)\n",
    "      aris.append(ARI)\n",
    "   print('Dataset:', dataset)\n",
    "   print(aris)\n",
    "   print(np.mean(aris))\n",
    "   with open('graphst_aris.txt', 'a+') as fp:\n",
    "      fp.write('mPFC' + dataset + ' ')\n",
    "      fp.write(' '.join([str(i) for i in aris]))\n",
    "      fp.write('\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. mHypothalamus dataset (6 slides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"mHypo\"\"\"\n",
    "setting_combinations = [[8, '-0.04'], [8, '-0.09'], [8, '-0.14'], [8, '-0.19'], [8, '-0.24'], [8, '-0.29']]\n",
    "for setting_combi in setting_combinations:\n",
    "   n_clusters = setting_combi[0]\n",
    "\n",
    "   dataset = setting_combi[1]  #\n",
    "   \n",
    "   dir_ = './benchmarking_data/mHypothalamus'\n",
    "   ad = load_mHypothalamus(root_dir=dir_, section_id=dataset)\n",
    "\n",
    "   aris = []\n",
    "   for iter in range(5):\n",
    "\n",
    "      \n",
    "      # print(ad)\n",
    "\n",
    "      # define model\n",
    "      model = GraphST.GraphST(ad, device=device)\n",
    "\n",
    "      # train model\n",
    "      ad = model.train()\n",
    "\n",
    "      # print(ad)\n",
    "\n",
    "      # set radius to specify the number of neighbors considered during refinement\n",
    "      radius = 50\n",
    "\n",
    "      tool = 'mclust' # mclust, leiden, and louvain\n",
    "\n",
    "      # clustering\n",
    "      if tool == 'mclust':\n",
    "         clustering(ad, n_clusters, radius=radius, method=tool, refinement=True) # For DLPFC dataset, we use optional refinement step.\n",
    "      elif tool in ['leiden', 'louvain']:\n",
    "         clustering(ad, n_clusters, radius=radius, method=tool, start=0.1, end=2.0, increment=0.01, refinement=False)\n",
    "\n",
    "      # filter out NA nodes\n",
    "      ad = ad[~pd.isnull(ad.obs['original_clusters'])]\n",
    "\n",
    "      # calculate metric ARI\n",
    "      ARI = metrics.adjusted_rand_score(ad.obs['domain'], ad.obs['original_clusters'])\n",
    "      ad.uns['ARI'] = ARI\n",
    "\n",
    "      # print('Dataset:', dataset)\n",
    "      # print('ARI:', ARI)\n",
    "      aris.append(ARI)\n",
    "   print('Dataset:', dataset)\n",
    "   print(aris)\n",
    "   print(np.mean(aris))\n",
    "   with open('graphst_aris.txt', 'a+') as fp:\n",
    "      fp.write('mHypothalamus' + dataset + ' ')\n",
    "      fp.write(' '.join([str(i) for i in aris]))\n",
    "      fp.write('\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Her2Tumor dataset (8 slides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Her2\"\"\"\n",
    "setting_combinations = [[6, 'A1'], [5, 'B1'], [4, 'C1'], [4, 'D1'], [4, 'E1'], [4, 'F1'], [7, 'G2'], [7, 'H1']]\n",
    "for setting_combi in setting_combinations:\n",
    "   n_clusters = setting_combi[0]\n",
    "\n",
    "   dataset = setting_combi[1]\n",
    "   \n",
    "   dir_ = './benchmarking_data/Her2_tumor'\n",
    "   ad = load_her2_tumor(root_dir=dir_, section_id=dataset)\n",
    "\n",
    "   aris = []\n",
    "   for iter in range(5):\n",
    "\n",
    "      \n",
    "      # print(ad)\n",
    "\n",
    "      # define model\n",
    "      model = GraphST.GraphST(ad, device=device)\n",
    "\n",
    "      # train model\n",
    "      ad = model.train()\n",
    "\n",
    "      # print(ad)\n",
    "\n",
    "      # set radius to specify the number of neighbors considered during refinement\n",
    "      radius = 50\n",
    "\n",
    "      tool = 'mclust' # mclust, leiden, and louvain\n",
    "\n",
    "      # clustering\n",
    "      if tool == 'mclust':\n",
    "         clustering(ad, n_clusters, radius=radius, method=tool, refinement=True) # For DLPFC dataset, we use optional refinement step.\n",
    "      elif tool in ['leiden', 'louvain']:\n",
    "         clustering(ad, n_clusters, radius=radius, method=tool, start=0.1, end=2.0, increment=0.01, refinement=False)\n",
    "\n",
    "      # filter out NA nodes\n",
    "      ad = ad[~pd.isnull(ad.obs['original_clusters'])]\n",
    "\n",
    "      # calculate metric ARI\n",
    "      ARI = metrics.adjusted_rand_score(ad.obs['domain'], ad.obs['original_clusters'])\n",
    "      ad.uns['ARI'] = ARI\n",
    "\n",
    "      # print('Dataset:', dataset)\n",
    "      # print('ARI:', ARI)\n",
    "      aris.append(ARI)\n",
    "   print('Dataset:', dataset)\n",
    "   print(aris)\n",
    "   print(np.mean(aris))\n",
    "   with open('graphst_aris.txt', 'a+') as fp:\n",
    "      fp.write('Her2tumor' + dataset + ' ')\n",
    "      fp.write(' '.join([str(i) for i in aris]))\n",
    "      fp.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GraphST",
   "language": "python",
   "name": "graphst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
