{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPACEL alignment tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SPACEL import Scube\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "\n",
    "from st_loading_utils import *\n",
    "import time\n",
    "\n",
    "iters = 1\n",
    "save_dir_gt = '/home/yunfei/spatial_benchmarking/BenchmarkST/sim_data_results/spacel'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mouse Hypothalamus data integration (pair-wise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"mhypo\"\"\"\n",
    "section_ids_list = [['-0.04', '-0.09'], ['-0.09', '-0.14'], ['-0.14', '-0.19'], ['-0.19', '-0.24']]\n",
    "run_times = []\n",
    "for iter_ in range(iters):\n",
    "    for section_ids in section_ids_list:\n",
    "        inputs = []\n",
    "\n",
    "        i = 0\n",
    "        for section_id in section_ids:\n",
    "            dataset = section_ids[0] + '_' + section_ids[1]\n",
    "            \n",
    "            print(dataset)\n",
    "            input_dir = '/home/yunfei/spatial_benchmarking/benchmarking_data/mHypothalamus/'\n",
    "            adata = load_mHypothalamus(root_dir=input_dir, section_id=section_id)\n",
    "            adata.var_names_make_unique(join=\"++\")\n",
    "            # print(adata.obsm['spatial'][:, 0])\n",
    "\n",
    "            \"\"\"rebuild obsm as used in scube\"\"\"\n",
    "            # print(adata.obs)\n",
    "            new_obsm = adata.obs[['x','y']]\n",
    "            new_obsm = new_obsm.rename(columns={'x': 'X', 'y': 'Y'})\n",
    "            new_obsm['Z'] = 0\n",
    "            new_obsm['X'] = adata.obsm['spatial'][:, 0]\n",
    "            new_obsm['Y'] = adata.obsm['spatial'][:, 1]\n",
    "            \n",
    "            print(adata.obs['original_clusters'])\n",
    "            # print(new_obsm)\n",
    "            adata.obsm['spatial'] = new_obsm\n",
    "            adata.obsm['spatial']['Z'] = i\n",
    "            i += 1\n",
    "            inputs.append(adata)\n",
    "\n",
    "        \n",
    "        start_time = time.time()\n",
    "        if not os.path.exists(os.path.join(save_dir_gt, dataset)):\n",
    "            os.makedirs(os.path.join(save_dir_gt, dataset))\n",
    "        save_path = os.path.join(save_dir_gt, dataset, 'iter'+str(iter_)+'aligned_coordinates.csv')\n",
    "        print(save_path)\n",
    "        Scube.align(inputs,cluster_key='original_clusters',n_neighbors=15,knn_exclude_cutoff=25,p=3, n_threads=10, write_loc_path=save_path)\n",
    "        # '/home/yunfei/spatial_benchmarking/mingxing_works/results/spacel/test/aligned_coordinates.csv'\n",
    "        \n",
    "        end_time = time.time()\n",
    "        run_times.append(end_time - start_time)\n",
    "\n",
    "        # save labels\n",
    "        labels = []\n",
    "        labels.extend(list(inputs[0].obs['original_clusters']))\n",
    "        labels.extend(list(inputs[1].obs['original_clusters']))\n",
    "        labels.extend(list(inputs[2].obs['original_clusters']))\n",
    "        labels.extend(list(inputs[3].obs['original_clusters']))\n",
    "        labels.extend(list(inputs[4].obs['original_clusters']))\n",
    "        np.save(os.path.join(save_dir_gt, dataset, 'iter'+str(iter_)+'labels.npy'), labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mouse Hypothalamus data integration (multi-slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"mhypo\"\"\"\n",
    "section_ids_list = [['-0.04', '-0.09', '-0.14', '-0.19', '-0.24']]\n",
    "run_times = []\n",
    "for iter_ in range(iters):\n",
    "    for section_ids in section_ids_list:\n",
    "        inputs = []\n",
    "\n",
    "        i = 0\n",
    "        for section_id in section_ids:\n",
    "            dataset = section_ids[0] + '_' + section_ids[1] + '_' + section_ids[2] + '_' + section_ids[3] + '_' + section_ids[4]\n",
    "            \n",
    "            print(dataset)\n",
    "            input_dir = '/home/yunfei/spatial_benchmarking/benchmarking_data/mHypothalamus/'\n",
    "            adata = load_mHypothalamus(root_dir=input_dir, section_id=section_id)\n",
    "            adata.var_names_make_unique(join=\"++\")\n",
    "            # print(adata.obsm['spatial'][:, 0])\n",
    "\n",
    "            \"\"\"rebuild obsm as used in scube\"\"\"\n",
    "            # print(adata.obs)\n",
    "            new_obsm = adata.obs[['x','y']]\n",
    "            new_obsm = new_obsm.rename(columns={'x': 'X', 'y': 'Y'})\n",
    "            new_obsm['Z'] = 0\n",
    "            new_obsm['X'] = adata.obsm['spatial'][:, 0]\n",
    "            new_obsm['Y'] = adata.obsm['spatial'][:, 1]\n",
    "            \n",
    "            print(adata.obs['original_clusters'])\n",
    "            # print(new_obsm)\n",
    "            adata.obsm['spatial'] = new_obsm\n",
    "            adata.obsm['spatial']['Z'] = i\n",
    "            i += 1\n",
    "            inputs.append(adata)\n",
    "\n",
    "        \n",
    "        start_time = time.time()\n",
    "        if not os.path.exists(os.path.join(save_dir_gt, dataset)):\n",
    "            os.makedirs(os.path.join(save_dir_gt, dataset))\n",
    "        save_path = os.path.join(save_dir_gt, dataset, 'iter'+str(iter_)+'aligned_coordinates.csv')\n",
    "        print(save_path)\n",
    "        Scube.align(inputs,cluster_key='original_clusters',n_neighbors=15,knn_exclude_cutoff=25,p=3, n_threads=10, write_loc_path=save_path)\n",
    "        # '/home/yunfei/spatial_benchmarking/mingxing_works/results/spacel/test/aligned_coordinates.csv'\n",
    "        \n",
    "        end_time = time.time()\n",
    "        run_times.append(end_time - start_time)\n",
    "\n",
    "        # save labels\n",
    "        labels = []\n",
    "        labels.extend(list(inputs[0].obs['original_clusters']))\n",
    "        labels.extend(list(inputs[1].obs['original_clusters']))\n",
    "        labels.extend(list(inputs[2].obs['original_clusters']))\n",
    "        labels.extend(list(inputs[3].obs['original_clusters']))\n",
    "        labels.extend(list(inputs[4].obs['original_clusters']))\n",
    "        np.save(os.path.join(save_dir_gt, dataset, 'iter'+str(iter_)+'labels.npy'), labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DLPFC data integration (pair-wise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_ids_list = [['151507', '151508'], ['151508', '151509'], ['151509', '151510'], ['151669', '151670'], ['151670', '151671'], ['151671', '151672'], ['151673', '151674'], ['151674', '151675'], ['151675', '151676']]\n",
    "run_times = []\n",
    "for iter_ in range(iters):\n",
    "    for section_ids in section_ids_list:\n",
    "        inputs = []\n",
    "\n",
    "        i = 0\n",
    "        for section_id in section_ids:\n",
    "            dataset = section_ids[0] + '_' + section_ids[1]\n",
    "            \n",
    "            print(dataset)\n",
    "            input_dir = '/home/yunfei/spatial_benchmarking/benchmarking_data/DLPFC12/'\n",
    "            adata = load_DLPFC(root_dir=input_dir, section_id=section_id)\n",
    "            adata.var_names_make_unique(join=\"++\")\n",
    "            # print(adata.obsm['spatial'][:, 0])\n",
    "\n",
    "            \"\"\"rebuild obsm as used in scube\"\"\"\n",
    "            # print(adata.obs)\n",
    "            new_obsm = adata.obs[['array_row','array_col']]\n",
    "            new_obsm = new_obsm.rename(columns={'array_row': 'X', 'array_col': 'Y'})\n",
    "            new_obsm['Z'] = 0\n",
    "            new_obsm['X'] = adata.obsm['spatial'][:, 0]\n",
    "            new_obsm['Y'] = adata.obsm['spatial'][:, 1]\n",
    "            \n",
    "            print(adata.obs['original_clusters'])\n",
    "            # print(new_obsm)\n",
    "            adata.obsm['spatial'] = new_obsm\n",
    "            adata.obsm['spatial']['Z'] = i\n",
    "            i += 1\n",
    "            inputs.append(adata)\n",
    "\n",
    "        # colors = sns.color_palette(n_colors=7)\n",
    "        # colors = [matplotlib.colors.to_hex(c) for c in colors]\n",
    "\n",
    "        # color_map = pd.DataFrame(colors,columns=['color'])\n",
    "        # print(color_map)\n",
    "\n",
    "        # for i in range(len(inputs)):\n",
    "        #     inputs[i].obs['original_clusters'] = inputs[i].obs['original_clusters'].astype('int').astype('category')\n",
    "        #     # print(inputs[i].obs['original_clusters'].unique())\n",
    "        #     inputs[i].uns['spa_cluster_colors'] = [color_map.loc[c,'color'] for c in inputs[i].obs['original_clusters'].cat.categories]\n",
    "        \n",
    "        start_time = time.time()\n",
    "        if not os.path.exists(os.path.join(save_dir_gt, dataset)):\n",
    "            os.makedirs(os.path.join(save_dir_gt, dataset))\n",
    "        save_path = os.path.join(save_dir_gt, dataset, 'iter'+str(iter_)+'aligned_coordinates.csv')\n",
    "        print(save_path)\n",
    "        Scube.align(inputs,cluster_key='original_clusters',n_neighbors=15,knn_exclude_cutoff=25,p=3, n_threads=10, write_loc_path=save_path)\n",
    "        # '/home/yunfei/spatial_benchmarking/mingxing_works/results/spacel/test/aligned_coordinates.csv'\n",
    "        \n",
    "        end_time = time.time()\n",
    "        run_times.append(end_time - start_time)\n",
    "\n",
    "        # save labels\n",
    "        labels = []\n",
    "        labels.extend(list(inputs[0].obs['original_clusters']))\n",
    "        labels.extend(list(inputs[1].obs['original_clusters']))\n",
    "        labels.extend(list(inputs[2].obs['original_clusters']))\n",
    "        labels.extend(list(inputs[3].obs['original_clusters']))\n",
    "        np.save(os.path.join(save_dir_gt, dataset, 'iter'+str(iter_)+'labels.npy'), labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mouse Hypothalamus data integration (multi-slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_ids_list = [['151507', '151508', '151509', '151510'], ['151669', '151670', '151671', '151672'], ['151673', '151674', '151675', '151676']]\n",
    "run_times = []\n",
    "for iter_ in range(iters):\n",
    "    for section_ids in section_ids_list:\n",
    "        inputs = []\n",
    "\n",
    "        i = 0\n",
    "        for section_id in section_ids:\n",
    "            dataset = section_ids[0] + '_' + section_ids[1] + '_' + section_ids[2] + '_' + section_ids[3]\n",
    "            \n",
    "            print(dataset)\n",
    "            input_dir = '/home/yunfei/spatial_benchmarking/benchmarking_data/DLPFC12/'\n",
    "            adata = load_DLPFC(root_dir=input_dir, section_id=section_id)\n",
    "            adata.var_names_make_unique(join=\"++\")\n",
    "            # print(adata.obsm['spatial'][:, 0])\n",
    "\n",
    "            \"\"\"rebuild obsm as used in scube\"\"\"\n",
    "            # print(adata.obs)\n",
    "            new_obsm = adata.obs[['array_row','array_col']]\n",
    "            new_obsm = new_obsm.rename(columns={'array_row': 'X', 'array_col': 'Y'})\n",
    "            new_obsm['Z'] = 0\n",
    "            new_obsm['X'] = adata.obsm['spatial'][:, 0]\n",
    "            new_obsm['Y'] = adata.obsm['spatial'][:, 1]\n",
    "            \n",
    "            print(adata.obs['original_clusters'])\n",
    "            # print(new_obsm)\n",
    "            adata.obsm['spatial'] = new_obsm\n",
    "            adata.obsm['spatial']['Z'] = i\n",
    "            i += 1\n",
    "            inputs.append(adata)\n",
    "\n",
    "        # colors = sns.color_palette(n_colors=7)\n",
    "        # colors = [matplotlib.colors.to_hex(c) for c in colors]\n",
    "\n",
    "        # color_map = pd.DataFrame(colors,columns=['color'])\n",
    "        # print(color_map)\n",
    "\n",
    "        # for i in range(len(inputs)):\n",
    "        #     inputs[i].obs['original_clusters'] = inputs[i].obs['original_clusters'].astype('int').astype('category')\n",
    "        #     # print(inputs[i].obs['original_clusters'].unique())\n",
    "        #     inputs[i].uns['spa_cluster_colors'] = [color_map.loc[c,'color'] for c in inputs[i].obs['original_clusters'].cat.categories]\n",
    "        \n",
    "        start_time = time.time()\n",
    "        if not os.path.exists(os.path.join(save_dir_gt, dataset)):\n",
    "            os.makedirs(os.path.join(save_dir_gt, dataset))\n",
    "        save_path = os.path.join(save_dir_gt, dataset, 'iter'+str(iter_)+'aligned_coordinates.csv')\n",
    "        print(save_path)\n",
    "        Scube.align(inputs,cluster_key='original_clusters',n_neighbors=15,knn_exclude_cutoff=25,p=3, n_threads=10, write_loc_path=save_path)\n",
    "        # '/home/yunfei/spatial_benchmarking/mingxing_works/results/spacel/test/aligned_coordinates.csv'\n",
    "        \n",
    "        end_time = time.time()\n",
    "        run_times.append(end_time - start_time)\n",
    "\n",
    "        # save labels\n",
    "        labels = []\n",
    "        labels.extend(list(inputs[0].obs['original_clusters']))\n",
    "        labels.extend(list(inputs[1].obs['original_clusters']))\n",
    "        labels.extend(list(inputs[2].obs['original_clusters']))\n",
    "        labels.extend(list(inputs[3].obs['original_clusters']))\n",
    "        np.save(os.path.join(save_dir_gt, dataset, 'iter'+str(iter_)+'labels.npy'), labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SPACEL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
