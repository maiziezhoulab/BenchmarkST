{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPSA alignment tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import anndata\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from gpsa import VariationalGPSA\n",
    "from gpsa import matern12_kernel, rbf_kernel\n",
    "from gpsa.plotting import callback_twod\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "from st_loading_functions import load_mHypothalamus, load_DLPFC\n",
    "import scanpy as sc\n",
    "from sklearn.neighbors import NearestNeighbors, KNeighborsRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "iters = 1\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def scale_spatial_coords(X, max_val=10.0):\n",
    "    X = X - X.min(0)\n",
    "    X = X / X.max(0)\n",
    "    return X * max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(adata, n_top_genes=2000):\n",
    "    adata.var_names_make_unique()\n",
    "    adata.var[\"mt\"] = adata.var_names.str.startswith(\"MT-\")\n",
    "    sc.pp.calculate_qc_metrics(adata, qc_vars=[\"mt\"], inplace=True)\n",
    "\n",
    "    # sc.pp.filter_cells(adata, min_counts=5000)\n",
    "    sc.pp.filter_cells(adata, max_counts=35000)\n",
    "    # adata = adata[adata.obs[\"pct_counts_mt\"] < 20]\n",
    "    sc.pp.filter_genes(adata, min_cells=10)\n",
    "\n",
    "    sc.pp.normalize_total(adata, inplace=True)\n",
    "    sc.pp.log1p(adata)\n",
    "    sc.pp.highly_variable_genes(\n",
    "        adata, flavor=\"seurat\", n_top_genes=n_top_genes, subset=True\n",
    "    )\n",
    "    return adata\n",
    "\n",
    "def train(model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    # Forward pass\n",
    "    G_means, G_samples, F_latent_samples, F_samples = model.forward(\n",
    "        X_spatial={\"expression\": x}, view_idx=view_idx, Ns=Ns, S=5\n",
    "    )\n",
    "\n",
    "    # Compute loss\n",
    "    loss = loss_fn(data_dict, F_samples)\n",
    "\n",
    "    # Compute gradients and take optimizer step\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item(), G_means\n",
    "\n",
    "save_dir_time = '/maiziezhou_lab/yunfei/Projects/spatial_benchmarking/spatial-alignment/results'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DLPFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_GENES = 10\n",
    "N_SAMPLES = None\n",
    "\n",
    "n_spatial_dims = 2\n",
    "n_views = 2\n",
    "m_G = 200\n",
    "m_X_per_view = 200\n",
    "\n",
    "N_LATENT_GPS = {\"expression\": None}\n",
    "\n",
    "N_EPOCHS =  5000\n",
    "PRINT_EVERY = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"DLPFC\"\"\" \n",
    "section_ids_list = [['151507', '151508'], ['151508', '151509'], ['151509', '151510'], ['151669', '151670'], ['151670', '151671'], ['151671', '151672'], ['151673', '151674'], ['151674', '151675'], ['151675', '151676']]\n",
    "run_times = []\n",
    "for iter_ in range(iters):\n",
    "    for section_ids in section_ids_list:\n",
    "        dataset = section_ids[0] + '_' + section_ids[1]\n",
    "        start_time = time.time()\n",
    "        output = '.'\n",
    "        data_slice1 = load_DLPFC(root_dir=\"../benchmarking_data/DLPFC12\", section_id=section_ids[0])\n",
    "        data_slice1 = process_data(data_slice1, n_top_genes=200)\n",
    "        data_slice1.obs['batch'] = 0\n",
    "        data_slice2 = load_DLPFC(root_dir=\"../benchmarking_data/DLPFC12\", section_id=section_ids[1])\n",
    "        data_slice2 = process_data(data_slice2, n_top_genes=200)\n",
    "        data_slice2.obs['batch'] = 1\n",
    "\n",
    "        data = anndata.concat([data_slice1, data_slice2])\n",
    "\n",
    "        if N_SAMPLES is not None:\n",
    "            rand_idx = np.random.choice(\n",
    "                np.arange(data_slice1.shape[0]), size=N_SAMPLES, replace=False\n",
    "            )\n",
    "            data_slice1 = data_slice1[rand_idx]\n",
    "            rand_idx = np.random.choice(\n",
    "                np.arange(data_slice2.shape[0]), size=N_SAMPLES, replace=False\n",
    "            )\n",
    "            data_slice2 = data_slice2[rand_idx]\n",
    "\n",
    "        # all_slices = anndata.concat([data_slice1, data_slice2])\n",
    "        n_samples_list = [data_slice1.shape[0], data_slice2.shape[0]]\n",
    "        view_idx = [\n",
    "            np.arange(data_slice1.shape[0]),\n",
    "            np.arange(data_slice1.shape[0], data_slice1.shape[0] + data_slice2.shape[0]),\n",
    "        ]\n",
    "\n",
    "        X1 = data_slice1.obsm[\"spatial\"]\n",
    "        X2 = data_slice2.obsm[\"spatial\"]\n",
    "        Y1 = data_slice1.X.todense()\n",
    "        Y2 = data_slice2.X.todense()\n",
    "\n",
    "        X1 = scale_spatial_coords(X1)\n",
    "        X2 = scale_spatial_coords(X2)\n",
    "\n",
    "        Y1 = (Y1 - Y1.mean(0)) / Y1.std(0)\n",
    "        Y2 = (Y2 - Y2.mean(0)) / Y2.std(0)\n",
    "\n",
    "        X = np.concatenate([X1, X2])\n",
    "\n",
    "        Y = np.concatenate([Y1, Y2])\n",
    "\n",
    "        n_outputs = Y.shape[1]\n",
    "\n",
    "        x = torch.from_numpy(X).float().clone().to(device)\n",
    "        y = torch.from_numpy(Y).float().clone().to(device)\n",
    "\n",
    "        data_dict = {\n",
    "            \"expression\": {\n",
    "                \"spatial_coords\": x,\n",
    "                \"outputs\": y,\n",
    "                \"n_samples_list\": n_samples_list,\n",
    "            }\n",
    "        }\n",
    "\n",
    "        model = VariationalGPSA(\n",
    "            data_dict,\n",
    "            n_spatial_dims=n_spatial_dims,\n",
    "            m_X_per_view=m_X_per_view,\n",
    "            m_G=m_G,\n",
    "            data_init=True,\n",
    "            minmax_init=False,\n",
    "            grid_init=False,\n",
    "            n_latent_gps=N_LATENT_GPS,\n",
    "            mean_function=\"identity_fixed\",\n",
    "            kernel_func_warp=rbf_kernel,\n",
    "            kernel_func_data=rbf_kernel,\n",
    "            # fixed_warp_kernel_variances=np.ones(n_views) * 1.,\n",
    "            # fixed_warp_kernel_lengthscales=np.ones(n_views) * 10,\n",
    "            fixed_view_idx=0,\n",
    "        ).to(device)\n",
    "\n",
    "        view_idx, Ns, _, _ = model.create_view_idx_dict(data_dict)\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "        for t in tqdm(range(N_EPOCHS), desc=\"Training Progress\"):\n",
    "            loss, G_means = train(model, model.loss_fn, optimizer)\n",
    "            curr_aligned_coords = G_means[\"expression\"].detach().cpu().numpy()\n",
    "        print(\"Done!\")\n",
    "\n",
    "        # G_means, _, _, _ = model.forward({\"expression\": x}, view_idx=view_idx, Ns=Ns)\n",
    "\n",
    "        # out = G_means['expression'].detach().cpu().numpy()\n",
    "        df3 = pd.DataFrame(\n",
    "            {\n",
    "                \"aligned_x\": curr_aligned_coords.T[0],\n",
    "                \"aligned_y\": curr_aligned_coords.T[1],\n",
    "            },\n",
    "        )\n",
    "        df3.index = data.obs.index\n",
    "\n",
    "        results = pd.concat([data.obs, df3], axis=1)\n",
    "        results.to_csv('./results/' + dataset + '_' + str(0) + '.csv')\n",
    "        end_time = time.time()\n",
    "        run_times.append(end_time - start_time)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
