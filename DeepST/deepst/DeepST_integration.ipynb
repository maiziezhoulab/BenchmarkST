{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepST integration tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yunfei/anaconda3/envs/DeepST/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "from DeepST import run\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import json\n",
    "import time\n",
    "import os.path as osp\n",
    "\n",
    "iters = 1\n",
    "save_dir_gt = '/home/yunfei/spatial_benchmarking/BenchmarkST/sim_data_results/deepst'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mouse Hypothalamus data integration (pair-wise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"mhypo\"\"\"\n",
    "\n",
    "section_ids_list = [['-0.04', '-0.09'], ['-0.09', '-0.14'], ['-0.14', '-0.19'], ['-0.19', '-0.24']]\n",
    "run_times = []\n",
    "\n",
    "for iter_ in range(iters):\n",
    "    for section_ids in section_ids_list:\n",
    "        dataset = section_ids[0] + '_' + section_ids[1]\n",
    "        start_time = time.time()\n",
    "        # slice1 = load_mHypothalamus(section_id=section_ids[0])\n",
    "        # slice2 = load_mHypothalamus(section_id=section_ids[1])\n",
    "\n",
    "        # run deeepst pairwise alignment\n",
    "        data_path = \"/home/yunfei/spatial_benchmarking/benchmarking_data/mHypothalamus\" \n",
    "        data_name_list = section_ids\n",
    "        save_path = \"../Results\" \n",
    "        n_domains = 8 \n",
    "        deepen = run(task = \"Integration\",\n",
    "            pre_epochs = 800, #### According to your own hardware, choose the number of training\n",
    "            epochs = 1000, #### According to your own hardware, choose the number of training\n",
    "            use_gpu = True\n",
    "            )\n",
    "        augement_data_list = []\n",
    "        graph_list = []\n",
    "        for i in range(len(section_ids)):\n",
    "            adata = deepen._get_adata(platform=\"benchmark_test\", data_path=data_path, data_name=data_name_list[i])\n",
    "            # adata = deepen._get_image_crop(adata, data_name=data_name_list[i])\n",
    "            # adata.obs = adata.obs.rename(columns={'imagerow': 'array_row', 'imagecol': 'array_col'})\n",
    "            # print(adata.obs)\n",
    "            adata = deepen._get_augment(adata, spatial_type=\"KDTree\", use_morphological=False)\n",
    "            graph_dict = deepen._get_graph(adata.obsm[\"spatial\"], distType = \"KDTree\")\n",
    "            augement_data_list.append(adata)\n",
    "            graph_list.append(graph_dict)\n",
    "\n",
    "        ######## Synthetic Datasets and Graphs\n",
    "        multiple_adata, multiple_graph = deepen._get_multiple_adata(adata_list = augement_data_list, data_name_list = data_name_list, graph_list = graph_list)\n",
    "\n",
    "        ###### Enhanced data preprocessing\n",
    "        data = deepen._data_process(multiple_adata, pca_n_comps = 150)\n",
    "\n",
    "        deepst_embed = deepen._fit(\n",
    "                data = data,\n",
    "                graph_dict = multiple_graph,\n",
    "                domains = multiple_adata.obs[\"batch\"].values,  ##### Input to Domain Adversarial Model\n",
    "                n_domains = len(data_name_list))\n",
    "        multiple_adata.obsm[\"DeepST_embed\"] = deepst_embed\n",
    "        multiple_adata = deepen._get_cluster_data(multiple_adata, n_domains=n_domains, priori = True)\n",
    "\n",
    "        # np.save(os.path.join(save_dir_r, 'deepst_' + sec1 + '_' + sec2 + '_iter_' + str(e) + '_deepst_embedding.npy'), adata.obsm['DeepST_embed'])\n",
    "\n",
    "        # save alignment matrix\n",
    "        if not os.path.exists(os.path.join(save_dir_gt, dataset)):\n",
    "            os.makedirs(os.path.join(save_dir_gt, dataset))\n",
    "        np.save(osp.join(save_dir_gt, dataset, 'iter'+str(iter_)+'embedding.npy'), multiple_adata.obsm['DeepST_embed'])\n",
    "        np.save(osp.join(save_dir_gt, dataset, 'iter'+str(iter_)+'prediction.npy'), multiple_adata.obs['DeepST_refine_domain'])\n",
    "\n",
    "        end_time = time.time()\n",
    "        run_times.append(end_time - start_time)\n",
    "\n",
    "        np.save(osp.join(save_dir_gt, dataset, 'iter'+str(iter_)+'labels.npy'), multiple_adata.obs['original_clusters'])\n",
    "\n",
    "        multiple_adata = deepen._get_cluster_data(multiple_adata, n_domains=n_domains, priori = True)\n",
    "        for data_name in data_name_list:\n",
    "            adata = multiple_adata[multiple_adata.obs[\"batch_name\"]==data_name]\n",
    "            np.save(osp.join(save_dir_gt, dataset, 'iter'+data_name+'_'+str(iter_)+'preds.npy'), adata.obs['DeepST_refine_domain'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DLPFC data integration (pair-wise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"dlpfc\"\"\"\n",
    "section_ids_list = [['151507', '151508'], ['151508', '151509'], ['151509', '151510'], ['151673', '151674'], ['151674', '151675'], ['151675', '151676']]\n",
    "run_times = []\n",
    "for section_ids in section_ids_list:\n",
    "    for iter_ in range(iters):\n",
    "        dataset = section_ids[0] + '_' + section_ids[1]\n",
    "        start_time = time.time()\n",
    "        # slice1 = load_mHypothalamus(section_id=section_ids[0])\n",
    "        # slice2 = load_mHypothalamus(section_id=section_ids[1])\n",
    "\n",
    "        # run deeepst pairwise alignment\n",
    "        data_path = \"/home/yunfei/spatial_benchmarking/benchmarking_data/DLPFC12\" \n",
    "        data_name_list = section_ids\n",
    "        save_path = \"../Results\" \n",
    "        n_domains = 7 \n",
    "        deepen = run(task = \"Integration\",\n",
    "            pre_epochs = 800, #### According to your own hardware, choose the number of training\n",
    "            epochs = 1000, #### According to your own hardware, choose the number of training\n",
    "            use_gpu = True\n",
    "            )\n",
    "        augement_data_list = []\n",
    "        graph_list = []\n",
    "        for i in range(len(section_ids)):\n",
    "            adata = deepen._get_adata(platform=\"Visium\", data_path=data_path, data_name=data_name_list[i])\n",
    "            # adata = deepen._get_image_crop(adata, data_name=data_name_list[i])\n",
    "            # adata.obs = adata.obs.rename(columns={'imagerow': 'array_row', 'imagecol': 'array_col'})\n",
    "            # print(adata.obs)\n",
    "            adata = deepen._get_augment(adata, spatial_type=\"KDTree\", use_morphological=False)\n",
    "            graph_dict = deepen._get_graph(adata.obsm[\"spatial\"], distType = \"KDTree\")\n",
    "            augement_data_list.append(adata)\n",
    "            graph_list.append(graph_dict)\n",
    "\n",
    "        ######## Synthetic Datasets and Graphs\n",
    "        multiple_adata, multiple_graph = deepen._get_multiple_adata(adata_list = augement_data_list, data_name_list = data_name_list, graph_list = graph_list)\n",
    "\n",
    "        ###### Enhanced data preprocessing\n",
    "        data = deepen._data_process(multiple_adata, pca_n_comps = 200)\n",
    "\n",
    "        deepst_embed = deepen._fit(\n",
    "                data = data,\n",
    "                graph_dict = multiple_graph,\n",
    "                domains = multiple_adata.obs[\"batch\"].values,  ##### Input to Domain Adversarial Model\n",
    "                n_domains = len(data_name_list))\n",
    "        multiple_adata.obsm[\"DeepST_embed\"] = deepst_embed\n",
    "        multiple_adata = deepen._get_cluster_data(multiple_adata, n_domains=n_domains, priori = True)\n",
    "\n",
    "        # np.save(os.path.join(save_dir_r, 'deepst_' + sec1 + '_' + sec2 + '_iter_' + str(e) + '_deepst_embedding.npy'), adata.obsm['DeepST_embed'])\n",
    "\n",
    "        # save alignment matrix\n",
    "        if not os.path.exists(os.path.join(save_dir_gt, dataset)):\n",
    "            os.makedirs(os.path.join(save_dir_gt, dataset))\n",
    "        np.save(osp.join(save_dir_gt, dataset, 'iter'+str(iter_)+'embedding.npy'), multiple_adata.obsm['DeepST_embed'])\n",
    "        np.save(osp.join(save_dir_gt, dataset, 'iter'+str(iter_)+'prediction.npy'), multiple_adata.obs['DeepST_refine_domain'])\n",
    "\n",
    "        end_time = time.time()\n",
    "        run_times.append(end_time - start_time)\n",
    "\n",
    "        # save labels\n",
    "        np.save(osp.join(save_dir_gt, dataset, 'iter'+str(iter_)+'labels.npy'), multiple_adata.obs['original_clusters'])\n",
    "        multiple_adata = deepen._get_cluster_data(multiple_adata, n_domains=n_domains, priori = True)\n",
    "        for data_name in data_name_list:\n",
    "            adata = multiple_adata[multiple_adata.obs[\"batch_name\"]==data_name]\n",
    "            np.save(osp.join(save_dir_gt, dataset, 'iter'+data_name+'_'+str(iter_)+'preds.npy'), adata.obs['DeepST_refine_domain'])\n",
    "\n",
    "\n",
    "section_ids_list = [['151669', '151670'], ['151670', '151671'], ['151671', '151672']]\n",
    "run_times = []\n",
    "for section_ids in section_ids_list:\n",
    "    for iter_ in range(iters):\n",
    "        dataset = section_ids[0] + '_' + section_ids[1]\n",
    "        start_time = time.time()\n",
    "        # slice1 = load_mHypothalamus(section_id=section_ids[0])\n",
    "        # slice2 = load_mHypothalamus(section_id=section_ids[1])\n",
    "\n",
    "        # run deeepst pairwise alignment\n",
    "        data_path = \"/home/yunfei/spatial_benchmarking/benchmarking_data/DLPFC12\" \n",
    "        data_name_list = section_ids\n",
    "        save_path = \"../Results\" \n",
    "        n_domains = 5\n",
    "        deepen = run(task = \"Integration\",\n",
    "            pre_epochs = 800, #### According to your own hardware, choose the number of training\n",
    "            epochs = 1000, #### According to your own hardware, choose the number of training\n",
    "            use_gpu = True\n",
    "            )\n",
    "        augement_data_list = []\n",
    "        graph_list = []\n",
    "        for i in range(len(section_ids)):\n",
    "            adata = deepen._get_adata(platform=\"Visium\", data_path=data_path, data_name=data_name_list[i])\n",
    "            # adata = deepen._get_image_crop(adata, data_name=data_name_list[i])\n",
    "            # adata.obs = adata.obs.rename(columns={'imagerow': 'array_row', 'imagecol': 'array_col'})\n",
    "            # print(adata.obs)\n",
    "            adata = deepen._get_augment(adata, spatial_type=\"KDTree\", use_morphological=False)\n",
    "            graph_dict = deepen._get_graph(adata.obsm[\"spatial\"], distType = \"KDTree\")\n",
    "            augement_data_list.append(adata)\n",
    "            graph_list.append(graph_dict)\n",
    "\n",
    "        ######## Synthetic Datasets and Graphs\n",
    "        multiple_adata, multiple_graph = deepen._get_multiple_adata(adata_list = augement_data_list, data_name_list = data_name_list, graph_list = graph_list)\n",
    "\n",
    "        ###### Enhanced data preprocessing\n",
    "        data = deepen._data_process(multiple_adata, pca_n_comps = 200)\n",
    "\n",
    "        deepst_embed = deepen._fit(\n",
    "                data = data,\n",
    "                graph_dict = multiple_graph,\n",
    "                domains = multiple_adata.obs[\"batch\"].values,  ##### Input to Domain Adversarial Model\n",
    "                n_domains = len(data_name_list))\n",
    "        multiple_adata.obsm[\"DeepST_embed\"] = deepst_embed\n",
    "        multiple_adata = deepen._get_cluster_data(multiple_adata, n_domains=n_domains, priori = True)\n",
    "\n",
    "        # np.save(os.path.join(save_dir_r, 'deepst_' + sec1 + '_' + sec2 + '_iter_' + str(e) + '_deepst_embedding.npy'), adata.obsm['DeepST_embed'])\n",
    "\n",
    "        # save alignment matrix\n",
    "        if not os.path.exists(os.path.join(save_dir_gt, dataset)):\n",
    "            os.makedirs(os.path.join(save_dir_gt, dataset))\n",
    "        np.save(osp.join(save_dir_gt, dataset, 'iter'+str(iter_)+'embedding.npy'), multiple_adata.obsm['DeepST_embed'])\n",
    "        np.save(osp.join(save_dir_gt, dataset, 'iter'+str(iter_)+'prediction.npy'), multiple_adata.obs['DeepST_refine_domain'])\n",
    "\n",
    "        end_time = time.time()\n",
    "        run_times.append(end_time - start_time)\n",
    "\n",
    "        # save labels\n",
    "        np.save(osp.join(save_dir_gt, dataset, 'iter'+str(iter_)+'labels.npy'), multiple_adata.obs['original_clusters'])\n",
    "        multiple_adata = deepen._get_cluster_data(multiple_adata, n_domains=n_domains, priori = True)\n",
    "        for data_name in data_name_list:\n",
    "            adata = multiple_adata[multiple_adata.obs[\"batch_name\"]==data_name]\n",
    "            np.save(osp.join(save_dir_gt, dataset, 'iter'+data_name+'_'+str(iter_)+'preds.npy'), adata.obs['DeepST_refine_domain'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mouse Hypothalamus data integration (multi-slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"mhypo\"\"\"\n",
    "\n",
    "section_ids_list = [['-0.04', '-0.09', '-0.14', '-0.19', '-0.24']]\n",
    "run_times = []\n",
    "\n",
    "for iter_ in range(iters):\n",
    "    for section_ids in section_ids_list:\n",
    "        dataset = section_ids[0] + '_' + section_ids[1] + '_' + section_ids[2] + '_' + section_ids[3] + '_' + section_ids[4]\n",
    "        start_time = time.time()\n",
    "\n",
    "        # run deeepst pairwise alignment\n",
    "        data_path = \"/home/yunfei/spatial_benchmarking/benchmarking_data/mHypothalamus\" \n",
    "        data_name_list = section_ids\n",
    "        save_path = \"../Results\" \n",
    "        n_domains = 8 \n",
    "        deepen = run(task = \"Integration\",\n",
    "            pre_epochs = 800, #### According to your own hardware, choose the number of training\n",
    "            epochs = 1000, #### According to your own hardware, choose the number of training\n",
    "            use_gpu = True\n",
    "            )\n",
    "        augement_data_list = []\n",
    "        graph_list = []\n",
    "        for i in range(len(section_ids)):\n",
    "            adata = deepen._get_adata(platform=\"benchmark_test\", data_path=data_path, data_name=data_name_list[i])\n",
    "            # adata = deepen._get_image_crop(adata, data_name=data_name_list[i])\n",
    "            # adata.obs = adata.obs.rename(columns={'imagerow': 'array_row', 'imagecol': 'array_col'})\n",
    "            # print(adata.obs)\n",
    "            adata = deepen._get_augment(adata, spatial_type=\"KDTree\", use_morphological=False)\n",
    "            graph_dict = deepen._get_graph(adata.obsm[\"spatial\"], distType = \"KDTree\")\n",
    "            augement_data_list.append(adata)\n",
    "            graph_list.append(graph_dict)\n",
    "\n",
    "        ######## Synthetic Datasets and Graphs\n",
    "        multiple_adata, multiple_graph = deepen._get_multiple_adata(adata_list = augement_data_list, data_name_list = data_name_list, graph_list = graph_list)\n",
    "\n",
    "        ###### Enhanced data preprocessing\n",
    "        data = deepen._data_process(multiple_adata, pca_n_comps = 150)\n",
    "\n",
    "        deepst_embed = deepen._fit(\n",
    "                data = data,\n",
    "                graph_dict = multiple_graph,\n",
    "                domains = multiple_adata.obs[\"batch\"].values,  ##### Input to Domain Adversarial Model\n",
    "                n_domains = len(data_name_list))\n",
    "        multiple_adata.obsm[\"DeepST_embed\"] = deepst_embed\n",
    "        multiple_adata = deepen._get_cluster_data(multiple_adata, n_domains=n_domains, priori = True)\n",
    "\n",
    "        # np.save(os.path.join(save_dir_r, 'deepst_' + sec1 + '_' + sec2 + '_iter_' + str(e) + '_deepst_embedding.npy'), adata.obsm['DeepST_embed'])\n",
    "\n",
    "        # save alignment matrix\n",
    "        if not os.path.exists(os.path.join(save_dir_gt, dataset)):\n",
    "            os.makedirs(os.path.join(save_dir_gt, dataset))\n",
    "        np.save(osp.join(save_dir_gt, dataset, 'iter'+str(iter_)+'embedding.npy'), multiple_adata.obsm['DeepST_embed'])\n",
    "        np.save(osp.join(save_dir_gt, dataset, 'iter'+str(iter_)+'prediction.npy'), multiple_adata.obs['DeepST_refine_domain'])\n",
    "\n",
    "        end_time = time.time()\n",
    "        run_times.append(end_time - start_time)\n",
    "\n",
    "        np.save(osp.join(save_dir_gt, dataset, 'iter'+str(iter_)+'labels.npy'), multiple_adata.obs['original_clusters'])\n",
    "\n",
    "        multiple_adata = deepen._get_cluster_data(multiple_adata, n_domains=n_domains, priori = True)\n",
    "        for data_name in data_name_list:\n",
    "            adata = multiple_adata[multiple_adata.obs[\"batch_name\"]==data_name]\n",
    "            np.save(osp.join(save_dir_gt, dataset, 'iter'+data_name+'_'+str(iter_)+'preds.npy'), adata.obs['DeepST_refine_domain'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DLPFC data integration (multi-slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"dlpfc\"\"\"\n",
    "section_ids_list = [['151507', '151508', '151509', '151510'], ['151673', '151674', '151675', '151676']]\n",
    "run_times = []\n",
    "for section_ids in section_ids_list:\n",
    "    for iter_ in range(iters):\n",
    "        dataset = section_ids[0] + '_' + section_ids[1] + '_' + section_ids[2] + '_' + section_ids[3]\n",
    "        start_time = time.time()\n",
    "        # slice1 = load_mHypothalamus(section_id=section_ids[0])\n",
    "        # slice2 = load_mHypothalamus(section_id=section_ids[1])\n",
    "\n",
    "        # run deeepst pairwise alignment\n",
    "        data_path = \"/home/yunfei/spatial_benchmarking/benchmarking_data/DLPFC12\" \n",
    "        data_name_list = section_ids\n",
    "        save_path = \"../Results\" \n",
    "        n_domains = 7 \n",
    "        deepen = run(task = \"Integration\",\n",
    "            pre_epochs = 800, #### According to your own hardware, choose the number of training\n",
    "            epochs = 1000, #### According to your own hardware, choose the number of training\n",
    "            use_gpu = True\n",
    "            )\n",
    "        augement_data_list = []\n",
    "        graph_list = []\n",
    "        for i in range(len(section_ids)):\n",
    "            adata = deepen._get_adata(platform=\"Visium\", data_path=data_path, data_name=data_name_list[i])\n",
    "            # adata = deepen._get_image_crop(adata, data_name=data_name_list[i])\n",
    "            # adata.obs = adata.obs.rename(columns={'imagerow': 'array_row', 'imagecol': 'array_col'})\n",
    "            # print(adata.obs)\n",
    "            adata = deepen._get_augment(adata, spatial_type=\"KDTree\", use_morphological=False)\n",
    "            graph_dict = deepen._get_graph(adata.obsm[\"spatial\"], distType = \"KDTree\")\n",
    "            augement_data_list.append(adata)\n",
    "            graph_list.append(graph_dict)\n",
    "\n",
    "        ######## Synthetic Datasets and Graphs\n",
    "        multiple_adata, multiple_graph = deepen._get_multiple_adata(adata_list = augement_data_list, data_name_list = data_name_list, graph_list = graph_list)\n",
    "\n",
    "        ###### Enhanced data preprocessing\n",
    "        data = deepen._data_process(multiple_adata, pca_n_comps = 200)\n",
    "\n",
    "        deepst_embed = deepen._fit(\n",
    "                data = data,\n",
    "                graph_dict = multiple_graph,\n",
    "                domains = multiple_adata.obs[\"batch\"].values,  ##### Input to Domain Adversarial Model\n",
    "                n_domains = len(data_name_list))\n",
    "        multiple_adata.obsm[\"DeepST_embed\"] = deepst_embed\n",
    "        multiple_adata = deepen._get_cluster_data(multiple_adata, n_domains=n_domains, priori = True)\n",
    "\n",
    "        # np.save(os.path.join(save_dir_r, 'deepst_' + sec1 + '_' + sec2 + '_iter_' + str(e) + '_deepst_embedding.npy'), adata.obsm['DeepST_embed'])\n",
    "\n",
    "        # save alignment matrix\n",
    "        if not os.path.exists(os.path.join(save_dir_gt, dataset)):\n",
    "            os.makedirs(os.path.join(save_dir_gt, dataset))\n",
    "        np.save(osp.join(save_dir_gt, dataset, 'iter'+str(iter_)+'embedding.npy'), multiple_adata.obsm['DeepST_embed'])\n",
    "        np.save(osp.join(save_dir_gt, dataset, 'iter'+str(iter_)+'prediction.npy'), multiple_adata.obs['DeepST_refine_domain'])\n",
    "\n",
    "        end_time = time.time()\n",
    "        run_times.append(end_time - start_time)\n",
    "\n",
    "        # save labels\n",
    "        np.save(osp.join(save_dir_gt, dataset, 'iter'+str(iter_)+'labels.npy'), multiple_adata.obs['original_clusters'])\n",
    "        multiple_adata = deepen._get_cluster_data(multiple_adata, n_domains=n_domains, priori = True)\n",
    "        for data_name in data_name_list:\n",
    "            adata = multiple_adata[multiple_adata.obs[\"batch_name\"]==data_name]\n",
    "            np.save(osp.join(save_dir_gt, dataset, 'iter'+data_name+'_'+str(iter_)+'preds.npy'), adata.obs['DeepST_refine_domain'])\n",
    "\n",
    "\n",
    "section_ids_list = [['151669', '151670', '151671', '151672']]\n",
    "run_times = []\n",
    "for section_ids in section_ids_list:\n",
    "    for iter_ in range(iters):\n",
    "        dataset = section_ids[0] + '_' + section_ids[1] + '_' + section_ids[2] + '_' + section_ids[3]\n",
    "        start_time = time.time()\n",
    "        # slice1 = load_mHypothalamus(section_id=section_ids[0])\n",
    "        # slice2 = load_mHypothalamus(section_id=section_ids[1])\n",
    "\n",
    "        # run deeepst pairwise alignment\n",
    "        data_path = \"/home/yunfei/spatial_benchmarking/benchmarking_data/DLPFC12\" \n",
    "        data_name_list = section_ids\n",
    "        save_path = \"../Results\" \n",
    "        n_domains = 5\n",
    "        deepen = run(task = \"Integration\",\n",
    "            pre_epochs = 800, #### According to your own hardware, choose the number of training\n",
    "            epochs = 1000, #### According to your own hardware, choose the number of training\n",
    "            use_gpu = True\n",
    "            )\n",
    "        augement_data_list = []\n",
    "        graph_list = []\n",
    "        for i in range(len(section_ids)):\n",
    "            adata = deepen._get_adata(platform=\"Visium\", data_path=data_path, data_name=data_name_list[i])\n",
    "            # adata = deepen._get_image_crop(adata, data_name=data_name_list[i])\n",
    "            # adata.obs = adata.obs.rename(columns={'imagerow': 'array_row', 'imagecol': 'array_col'})\n",
    "            # print(adata.obs)\n",
    "            adata = deepen._get_augment(adata, spatial_type=\"KDTree\", use_morphological=False)\n",
    "            graph_dict = deepen._get_graph(adata.obsm[\"spatial\"], distType = \"KDTree\")\n",
    "            augement_data_list.append(adata)\n",
    "            graph_list.append(graph_dict)\n",
    "\n",
    "        ######## Synthetic Datasets and Graphs\n",
    "        multiple_adata, multiple_graph = deepen._get_multiple_adata(adata_list = augement_data_list, data_name_list = data_name_list, graph_list = graph_list)\n",
    "\n",
    "        ###### Enhanced data preprocessing\n",
    "        data = deepen._data_process(multiple_adata, pca_n_comps = 200)\n",
    "\n",
    "        deepst_embed = deepen._fit(\n",
    "                data = data,\n",
    "                graph_dict = multiple_graph,\n",
    "                domains = multiple_adata.obs[\"batch\"].values,  ##### Input to Domain Adversarial Model\n",
    "                n_domains = len(data_name_list))\n",
    "        multiple_adata.obsm[\"DeepST_embed\"] = deepst_embed\n",
    "        multiple_adata = deepen._get_cluster_data(multiple_adata, n_domains=n_domains, priori = True)\n",
    "\n",
    "        # np.save(os.path.join(save_dir_r, 'deepst_' + sec1 + '_' + sec2 + '_iter_' + str(e) + '_deepst_embedding.npy'), adata.obsm['DeepST_embed'])\n",
    "\n",
    "        # save alignment matrix\n",
    "        if not os.path.exists(os.path.join(save_dir_gt, dataset)):\n",
    "            os.makedirs(os.path.join(save_dir_gt, dataset))\n",
    "        np.save(osp.join(save_dir_gt, dataset, 'iter'+str(iter_)+'embedding.npy'), multiple_adata.obsm['DeepST_embed'])\n",
    "        np.save(osp.join(save_dir_gt, dataset, 'iter'+str(iter_)+'prediction.npy'), multiple_adata.obs['DeepST_refine_domain'])\n",
    "\n",
    "        end_time = time.time()\n",
    "        run_times.append(end_time - start_time)\n",
    "\n",
    "        # save labels\n",
    "        np.save(osp.join(save_dir_gt, dataset, 'iter'+str(iter_)+'labels.npy'), multiple_adata.obs['original_clusters'])\n",
    "        multiple_adata = deepen._get_cluster_data(multiple_adata, n_domains=n_domains, priori = True)\n",
    "        for data_name in data_name_list:\n",
    "            adata = multiple_adata[multiple_adata.obs[\"batch_name\"]==data_name]\n",
    "            np.save(osp.join(save_dir_gt, dataset, 'iter'+data_name+'_'+str(iter_)+'preds.npy'), adata.obs['DeepST_refine_domain'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepST",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
