{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. import packages and select GPU if accessible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from DeepST import run\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "import numpy as np\n",
    "#In order to read in image data, we need to install some package. Here we recommend package \"opencv\"\n",
    "#inatll opencv in python\n",
    "#!pip3 install opencv-python\n",
    "from st_loading_utils import load_DLPFC, load_BC, load_mVC, load_mPFC, load_mHypothalamus, load_her2_tumor, load_mMAMP\n",
    "\n",
    "iters = 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. DLPFC dataset (12 slides)\n",
    "\n",
    "change '${dir_}' to  'path/to/your/DLPFC/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"DLPFC\"\"\"\n",
    "setting_combinations = [[7, '151507'], [7, '151508'], [7, '151509'], [7, '151510'], [5, '151669'], [5, '151670'], [5, '151671'], [5, '151672'], [7, '151673'], [7, '151674'], [7, '151675'], [7, '151676']]\n",
    "for setting_combi in setting_combinations:\n",
    "   n_clusters = setting_combi[0]  # 7\n",
    "\n",
    "   dataset = setting_combi[1]  # '151673'\n",
    "   aris = []\n",
    "   dir_ = './benchmarking_data/DLPFC12'\n",
    "\n",
    "   save_path = '../results/' + dataset + '/'\n",
    "   deepen = run(save_path = save_path, \n",
    "                  platform = \"Visium\",\n",
    "                  pca_n_comps = 200,\n",
    "                  pre_epochs = 800, #### According to your own hardware, choose the number of training\n",
    "                  epochs = 1000, #### According to your own hardware, choose the number of training\n",
    "                  Conv_type=\"GCNConv\", #### you can choose GNN types. \n",
    "                  )\n",
    "   adata_ = deepen._get_adata(dir_, dataset)\n",
    "   \n",
    "   for iter_ in range(iters):\n",
    "      adata = deepen._get_augment(adata_, adjacent_weight = 0.3, neighbour_k = 4)\n",
    "      graph_dict = deepen._get_graph(adata.obsm[\"spatial\"], distType=\"BallTree\", k=12)\n",
    "      adata = deepen._fit(adata, graph_dict, pretrain = False)\n",
    "      adata = deepen._get_cluster_data(adata, n_domains = n_clusters, priori=True) ###### without using prior knowledge, setting priori = False.\n",
    "      print(adata.obs)\n",
    "\n",
    "      ARI = adjusted_rand_score(adata.obs[\"DeepST_refine_domain\"], adata.obs[\"original_clusters\"])\n",
    "      aris.append(ARI)\n",
    "      print(iter_)\n",
    "      print('Dataset:', dataset)\n",
    "      print(ARI)\n",
    "   print('Dataset:', dataset)\n",
    "   print(aris)\n",
    "   print(np.mean(aris))\n",
    "   with open('deepst_aris.txt', 'a+') as fp:\n",
    "      fp.write('DLPFC' + dataset + ' ')\n",
    "      fp.write(' '.join([str(i) for i in aris]))\n",
    "      fp.write('\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. BC/MA datasets (2 slides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"BC\"\"\"\n",
    "# the number of clusters\n",
    "setting_combinations = [[20, 'section1']]\n",
    "for setting_combi in setting_combinations:\n",
    "   n_clusters = setting_combi[0]  # 7\n",
    "\n",
    "   dataset = setting_combi[1]  #\n",
    "   aris = []\n",
    "   dir_ = './benchmarking_data/BC'\n",
    "\n",
    "   save_path = '../results/' + dataset + '/'\n",
    "   deepen = run(save_path = save_path, \n",
    "                   platform = \"Visium\",\n",
    "                   pca_n_comps = 200,\n",
    "                   pre_epochs = 800, #### According to your own hardware, choose the number of training\n",
    "                   epochs = 1000, #### According to your own hardware, choose the number of training\n",
    "                   Conv_type=\"GCNConv\", #### you can choose GNN types. \n",
    "                   )\n",
    "   adata_ = deepen._get_adata(dir_, dataset)\n",
    "   \n",
    "   for iter_ in range(iters):\n",
    "      adata = deepen._get_augment(adata_, adjacent_weight = 0.3, neighbour_k = 4)\n",
    "      graph_dict = deepen._get_graph(adata.obsm[\"spatial\"], distType=\"BallTree\", k=12)\n",
    "      adata = deepen._fit(adata, graph_dict, pretrain = False)\n",
    "      adata = deepen._get_cluster_data(adata, n_domains = n_clusters, priori=True) ###### without using prior knowledge, setting priori = False.\n",
    "      print(adata.obs)\n",
    "\n",
    "      ARI = adjusted_rand_score(adata.obs[\"DeepST_refine_domain\"], adata.obs[\"original_clusters\"])\n",
    "      aris.append(ARI)\n",
    "      print(iter_)\n",
    "      print('Dataset:', dataset)\n",
    "      print(ARI)\n",
    "   print('Dataset:', dataset)\n",
    "   print(aris)\n",
    "   print(np.mean(aris))\n",
    "   with open('deepst_aris.txt', 'a+') as fp:\n",
    "      fp.write('HBRC1 ')\n",
    "      fp.write(' '.join([str(i) for i in aris]))\n",
    "      fp.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"BC\"\"\"\n",
    "# the number of clusters\n",
    "setting_combinations = [[20, 'section1']]\n",
    "for setting_combi in setting_combinations:\n",
    "   n_clusters = setting_combi[0]  # 7\n",
    "\n",
    "   dataset = setting_combi[1]  #\n",
    "   aris = []\n",
    "   dir_ = './benchmarking_data/BC'\n",
    "\n",
    "   save_path = '../results/' + dataset + '/'\n",
    "   deepen = run(save_path = save_path, \n",
    "                   platform = \"Visium\",\n",
    "                   pca_n_comps = 200,\n",
    "                   pre_epochs = 800, #### According to your own hardware, choose the number of training\n",
    "                   epochs = 1000, #### According to your own hardware, choose the number of training\n",
    "                   Conv_type=\"GCNConv\", #### you can choose GNN types. \n",
    "                   )\n",
    "   adata_ = deepen._get_adata(dir_, dataset)\n",
    "   \n",
    "   for iter_ in range(iters):\n",
    "      adata = deepen._get_augment(adata_, adjacent_weight = 0.3, neighbour_k = 4)\n",
    "      graph_dict = deepen._get_graph(adata.obsm[\"spatial\"], distType=\"BallTree\", k=12)\n",
    "      adata = deepen._fit(adata, graph_dict, pretrain = False)\n",
    "      adata = deepen._get_cluster_data(adata, n_domains = n_clusters, priori=True) ###### without using prior knowledge, setting priori = False.\n",
    "      print(adata.obs)\n",
    "\n",
    "      ARI = adjusted_rand_score(adata.obs[\"DeepST_refine_domain\"], adata.obs[\"original_clusters\"])\n",
    "      aris.append(ARI)\n",
    "      print(iter_)\n",
    "      print('Dataset:', dataset)\n",
    "      print(ARI)\n",
    "   print('Dataset:', dataset)\n",
    "   print(aris)\n",
    "   print(np.mean(aris))\n",
    "   with open('deepst_aris.txt', 'a+') as fp:\n",
    "      fp.write('HBRC1 ')\n",
    "      fp.write(' '.join([str(i) for i in aris]))\n",
    "      fp.write('\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. mVC/mPFC datasets (4 slides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"mVC\"\"\"\n",
    "# the number of clusters\n",
    "setting_combinations = [[7, 'STARmap_20180505_BY3_1k.h5ad']]\n",
    "for setting_combi in setting_combinations:\n",
    "   n_clusters = setting_combi[0]\n",
    "\n",
    "   dataset = setting_combi[1]\n",
    "   aris = []\n",
    "   dir_ = './benchmarking_data/STARmap_mouse_visual_cortex'\n",
    "   \n",
    "   save_path = '../results/' + dataset + '/'\n",
    "   deepen = run(save_path = save_path, \n",
    "                   platform = \"benchmark_test\",\n",
    "                   pca_n_comps = 200,\n",
    "                   pre_epochs = 800, #### According to your own hardware, choose the number of training\n",
    "                   epochs = 1000, #### According to your own hardware, choose the number of training\n",
    "                   )\n",
    "   # adata_ = deepen._get_adata(dir_, dataset)\n",
    "   adata_, graph_dict = deepen._get_single_adata(dir_, dataset, weights=\"weights_matrix_nomd\") #### Augmentation without using morphological information\n",
    "   # adata_ = deepen._get_augment(adata_, adjacent_weight = 0.3, neighbour_k = 4)\n",
    "   # graph_dict = deepen._get_graph(adata_.obsm[\"spatial\"], distType=\"BallTree\", k=12)\n",
    "   for iter_ in range(iters):\n",
    "      \n",
    "      \n",
    "      adata = deepen._fit(adata_, graph_dict, pretrain = False)\n",
    "      adata = deepen._get_cluster_data(adata, n_domains = n_clusters, priori=True) ###### without using prior knowledge, setting priori = False.\n",
    "      print(adata.obs)\n",
    "\n",
    "      ARI = adjusted_rand_score(adata.obs[\"DeepST_refine_domain\"], adata.obs[\"original_clusters\"])\n",
    "      aris.append(ARI)\n",
    "      print(iter_)\n",
    "      print('Dataset:', dataset)\n",
    "      print(ARI)\n",
    "   print('Dataset:', dataset)\n",
    "   print(aris)\n",
    "   print(np.mean(aris))\n",
    "   with open('deepst_aris.txt', 'a+') as fp:\n",
    "      fp.write('mVC ')\n",
    "      fp.write(' '.join([str(i) for i in aris]))\n",
    "      fp.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"mPFC\"\"\"\n",
    "# the number of clusters\n",
    "setting_combinations = [[4, '20180417_BZ5_control'], [4, '20180419_BZ9_control'], [4, '20180424_BZ14_control']]\n",
    "for setting_combi in setting_combinations:\n",
    "   n_clusters = setting_combi[0]\n",
    "\n",
    "   dataset = setting_combi[1]\n",
    "   aris = []\n",
    "   dir_ = './benchmarking_data/STARmap_mouse_PFC'\n",
    "   \n",
    "   save_path = '../results/' + dataset + '/'\n",
    "   deepen = run(save_path = save_path, \n",
    "                   platform = \"benchmark_test\",\n",
    "                   pca_n_comps = 200,\n",
    "                   pre_epochs = 800, #### According to your own hardware, choose the number of training\n",
    "                   epochs = 1000, #### According to your own hardware, choose the number of training\n",
    "                   )\n",
    "   # adata_ = deepen._get_adata(dir_, dataset)\n",
    "   adata_, graph_dict = deepen._get_single_adata(dir_, dataset, weights=\"weights_matrix_nomd\") #### Augmentation without using morphological information\n",
    "   # adata_ = deepen._get_augment(adata_, adjacent_weight = 0.3, neighbour_k = 4)\n",
    "   # graph_dict = deepen._get_graph(adata_.obsm[\"spatial\"], distType=\"BallTree\", k=12)\n",
    "   for iter_ in range(iters):\n",
    "      \n",
    "      \n",
    "      adata = deepen._fit(adata_, graph_dict, pretrain = False)\n",
    "      adata = deepen._get_cluster_data(adata, n_domains = n_clusters, priori=True) ###### without using prior knowledge, setting priori = False.\n",
    "      print(adata.obs)\n",
    "\n",
    "      ARI = adjusted_rand_score(adata.obs[\"DeepST_refine_domain\"], adata.obs[\"original_clusters\"])\n",
    "      aris.append(ARI)\n",
    "      print(iter_)\n",
    "      print('Dataset:', dataset)\n",
    "      print(ARI)\n",
    "   print('Dataset:', dataset)\n",
    "   print(aris)\n",
    "   print(np.mean(aris))\n",
    "   with open('deepst_aris.txt', 'a+') as fp:\n",
    "      fp.write('mPFC' + dataset + ' ')\n",
    "      fp.write(' '.join([str(i) for i in aris]))\n",
    "      fp.write('\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. mHypothalamus dataset (6 slides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"mHypo\"\"\"\n",
    "setting_combinations = [[8, '-0.04'], [8, '-0.09'], [8, '-0.14'], [8, '-0.19'], [8, '-0.24'], [8, '-0.29']]\n",
    "\n",
    "for setting_combi in setting_combinations:\n",
    "   n_clusters = setting_combi[0]\n",
    "\n",
    "   dataset = setting_combi[1]\n",
    "   aris = []\n",
    "   dir_ = './benchmarking_data/mHypothalamus'\n",
    "   \n",
    "   save_path = '../results/' + dataset + '/'\n",
    "   deepen = run(save_path = save_path, \n",
    "                   platform = \"benchmark_test\",\n",
    "                   pca_n_comps = 200,\n",
    "                   pre_epochs = 800, #### According to your own hardware, choose the number of training\n",
    "                   epochs = 1000, #### According to your own hardware, choose the number of training\n",
    "                   )\n",
    "   # adata_ = deepen._get_adata(dir_, dataset)\n",
    "   adata_, graph_dict = deepen._get_single_adata(dir_, dataset, weights=\"weights_matrix_nomd\") #### Augmentation without using morphological information\n",
    "   # adata_ = deepen._get_augment(adata_, adjacent_weight = 0.3, neighbour_k = 4)\n",
    "   # graph_dict = deepen._get_graph(adata_.obsm[\"spatial\"], distType=\"BallTree\", k=12)\n",
    "   for iter_ in range(iters):\n",
    "      \n",
    "      \n",
    "      adata = deepen._fit(adata_, graph_dict, pretrain = False)\n",
    "      adata = deepen._get_cluster_data(adata, n_domains = n_clusters, priori=True) ###### without using prior knowledge, setting priori = False.\n",
    "      print(adata.obs)\n",
    "\n",
    "      ARI = adjusted_rand_score(adata.obs[\"DeepST_refine_domain\"], adata.obs[\"original_clusters\"])\n",
    "      aris.append(ARI)\n",
    "      print(iter_)\n",
    "      print('Dataset:', dataset)\n",
    "      print(ARI)\n",
    "   print('Dataset:', dataset)\n",
    "   print(aris)\n",
    "   print(np.mean(aris))\n",
    "   with open('deepst_aris.txt', 'a+') as fp:\n",
    "      fp.write('mHypothalamus' + dataset + ' ')\n",
    "      fp.write(' '.join([str(i) for i in aris]))\n",
    "      fp.write('\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Her2Tumor dataset (8 slides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Her2\"\"\"\n",
    "setting_combinations = [[6, 'A1'], [5, 'B1'], [4, 'C1'], [4, 'D1'], [4, 'E1'], [4, 'F1'], [7, 'G2'], [7, 'H1']]\n",
    "for setting_combi in setting_combinations:\n",
    "   n_clusters = setting_combi[0]\n",
    "\n",
    "   dataset = setting_combi[1]\n",
    "   aris = []\n",
    "   dir_ = './benchmarking_data/Her2_tumor'\n",
    "   \n",
    "   save_path = '../results/' + dataset + '/'\n",
    "   deepen = run(save_path = save_path, \n",
    "                   platform = \"benchmark_test\",\n",
    "                   pca_n_comps = 200,\n",
    "                   pre_epochs = 800, #### According to your own hardware, choose the number of training\n",
    "                   epochs = 1000, #### According to your own hardware, choose the number of training\n",
    "                   )\n",
    "   # adata_ = deepen._get_adata(dir_, dataset)\n",
    "   adata_, graph_dict = deepen._get_single_adata(dir_, dataset, weights=\"weights_matrix_nomd\") #### Augmentation without using morphological information\n",
    "   # adata_ = deepen._get_augment(adata_, adjacent_weight = 0.3, neighbour_k = 4)\n",
    "   # graph_dict = deepen._get_graph(adata_.obsm[\"spatial\"], distType=\"BallTree\", k=12)\n",
    "   for iter_ in range(iters):\n",
    "      \n",
    "      \n",
    "      adata = deepen._fit(adata_, graph_dict, pretrain = False)\n",
    "      adata = deepen._get_cluster_data(adata, n_domains = n_clusters, priori=True) ###### without using prior knowledge, setting priori = False.\n",
    "      print(adata.obs)\n",
    "\n",
    "      ARI = adjusted_rand_score(adata.obs[\"DeepST_refine_domain\"], adata.obs[\"original_clusters\"])\n",
    "      aris.append(ARI)\n",
    "      print(iter_)\n",
    "      print('Dataset:', dataset)\n",
    "      print(ARI)\n",
    "   print('Dataset:', dataset)\n",
    "   print(aris)\n",
    "   print(np.mean(aris))\n",
    "   with open('deepst_aris.txt', 'a+') as fp:\n",
    "      fp.write('Her2tumor' + dataset + ' ')\n",
    "      fp.write(' '.join([str(i) for i in aris]))\n",
    "      fp.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
